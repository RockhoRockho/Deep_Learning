{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20211125_4_íŒŒì´í† ì¹˜ë€.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlpLKhu5Zyk/S5BWRrLme1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RockhoRockho/Deep_Learning_Tensorflow/blob/main/20211125_4_%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98%EB%9E%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnDak2REhm14"
      },
      "source": [
        "# **1. Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoIgxXBriU7k"
      },
      "source": [
        "* PytorchëŠ” tensorflowì™€ í•¨ê»˜ ë”¥ëŸ¬ë‹ì—ì„œ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” framework\n",
        "* ì´ˆê¸°ì—ëŠ” Torchë¼ëŠ” ì´ë¦„ìœ¼ë¡œ Luaì–¸ì–´ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œìœ¼ë‚˜, ì´í›„ pythonê¸°ë°˜ìœ¼ë¡œ ë³€ê²½í•œ ê²ƒì´ Pytorchì„\n",
        "* New York ëŒ€í•™êµì™€ Facebookì´ ê³µë™ìœ¼ë¡œ ë§Œë“¤ì—ˆê³ , ê°€ì¥ ëŒ€ì¤‘ì ìœ¼ë¡œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” frameworkì„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXlOGyznikZ1"
      },
      "source": [
        "# **2. Pytorch import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyyS8E4ejDhT"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRd9lo-DjGMy"
      },
      "source": [
        "### 2-1. Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co9Rinohjgks"
      },
      "source": [
        "* í…ì„œ(tensor)ëŠ” ë°°ì—´(array)ì´ë‚˜ í–‰ë ¬(matrix)ê³¼ ë§¤ìš° ìœ ì‚¬í•œ íŠ¹ìˆ˜í•œ ìë£Œêµ¬ì¡°\n",
        "* Pytorchì—ì„œëŠ” í…ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì…ë ¥(input)ê³¼ ì¶œë ¥(output), ê·¸ë¦¬ê³  ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë“¤ì„ ë¶€í˜¸í™”(encode)í•¨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ubJsPy9jwvt"
      },
      "source": [
        "# listë¡œë¶€í„° ì§ì ‘ tensor ìƒì„±\n",
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(x_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL3zOqCGkIZG"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndq8Aj-fj3T0"
      },
      "source": [
        "# numpy arrayë¡œë¶€í„° tensor ìƒì„±\n",
        "np_array = np.array(data)\n",
        "x_np_1 = torch.tensor(data) # ì¹´í”¼ë¥¼ ë§Œë“¬(ìƒˆë¡œìš´ í…ì„œ, ë©”ëª¨ë¦¬ë‚­ë¹„)\n",
        "print(x_np_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg86jY4kkJ1U"
      },
      "source": [
        "x_np_2 = torch.as_tensor(np_array) # ë·°ë¥¼ë§Œë“¦\n",
        "print(x_np_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLEARon_kabL"
      },
      "source": [
        "x_np_3 = torch.from_numpy(np_array) # ë·°ë¥¼ë§Œë“¦\n",
        "print(x_np_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNT2oLjwkeNj"
      },
      "source": [
        "x_np_1[0, 0] = 5\n",
        "print(x_np_1)\n",
        "print(np_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6OcPU7FkqvL"
      },
      "source": [
        "x_np_2[0, 0] = 6\n",
        "print(x_np_2)\n",
        "print(np_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPbYwD-sk17b"
      },
      "source": [
        "x_np_3[0, 0] = 7\n",
        "print(x_np_3)\n",
        "print(np_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOE8hLHwlDxs"
      },
      "source": [
        "np_again = x_np_1.numpy()\n",
        "print(np_again, type(np_again))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63bCOxwrlkOs"
      },
      "source": [
        "a = torch.ones(2, 3)\n",
        "print(a)\n",
        "b = torch.zeros(2, 3)\n",
        "print(b)\n",
        "c = torch.full((2, 3), 2)\n",
        "print(c)\n",
        "d = torch.empty(2, 3)\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uLS0jW6l4RT"
      },
      "source": [
        "e = torch.zeros_like(c)\n",
        "print(e)\n",
        "f = torch.ones_like(c)\n",
        "print(f)\n",
        "g = torch.full_like(c, 3)\n",
        "print(g)\n",
        "h = torch.empty_like(c)\n",
        "print(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xssgf2il-rr"
      },
      "source": [
        "i = torch.eye(3)\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMMUzscJmaVs"
      },
      "source": [
        "j = torch.arange(10)\n",
        "print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r7CIEv9mcIr"
      },
      "source": [
        "k = torch.rand(2, 2)\n",
        "l = torch.randn(2, 2)\n",
        "print(k)\n",
        "print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iflnXvnynKc5"
      },
      "source": [
        "### **2-2 Tensor ì†ì„±**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7RWXGrCmgXs"
      },
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f'Shape of tensor: {tensor.shape}')\n",
        "print(f'DataType of tensor: {tensor.dtype}')\n",
        "print(f'Device tensor: {tensor.device}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtSIj1Gfns0u"
      },
      "source": [
        "# ì†ì„± ë³€ê²½\n",
        "tensor = tensor.reshape(4, 3)\n",
        "tensor = tensor.int()\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('gpu') # í™•ì¸ !\n",
        "\n",
        "print(f'Shape of tensor: {tensor.shape}')\n",
        "print(f'DataType of tensor: {tensor.dtype}')\n",
        "print(f'Device tensor: {tensor.device}') # í™•ì¸!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjqKix_5oFSN"
      },
      "source": [
        "### **2-3 Indexingê³¼ Slicing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQMsMDjo3Pk"
      },
      "source": [
        "a = torch.arange(1, 13).reshape(3, 4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhXnnEadpF_M"
      },
      "source": [
        "# Indexing\n",
        "print(a[1])\n",
        "print(a[0, -1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQmdhRCTpOnM"
      },
      "source": [
        "# Slicing\n",
        "print(a[1:-1])\n",
        "print(a[:2, 2:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKKpKHGrpX5M"
      },
      "source": [
        "### **2-4 Transpose**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdrOKOXPpkY1"
      },
      "source": [
        "a = torch.arange(16).reshape(2, 2, 4) # (0, 1, 2) ì˜ë¯¸\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUog4xeTpn_s"
      },
      "source": [
        "b = a.transpose(1, 2) # (0, 2, 1)ë¡œ ë³€í™˜\n",
        "print(b, b.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1zIKvOvp_Gc"
      },
      "source": [
        "c = a.permute((2, 0, 1)) # (2, 0, 1)ë¡œ ë³€í™˜\n",
        "print(c, c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1YuDCpLqFPM"
      },
      "source": [
        "### 2-5 Tensor ì—°ì‚°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiDaLWUAtNVV"
      },
      "source": [
        "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMH8CaRrtXXM"
      },
      "source": [
        "print(x + y)\n",
        "print(x - y)\n",
        "print(x * y)\n",
        "print(x / y)\n",
        "print(x @ y)\n",
        "print('ğŸ˜'*30)\n",
        "print(torch.add(x, y))\n",
        "print(torch.subtract(x, y))\n",
        "print(torch.multiply(x, y))\n",
        "print(torch.divide(x, y))\n",
        "print(torch.matmul(x, y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzeD66KxtdnS"
      },
      "source": [
        "# in-place ì—°ì‚°\n",
        "print(x.add(y))\n",
        "print(x)\n",
        "\n",
        "print(x.add_(y)) # xì— ê²°ê³¼ê°€ ë‹¤ì‹œ ì €ì¥\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_cyyfe_vBPM"
      },
      "source": [
        "z = torch.arange(1, 11).reshape(2, 5)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlO0SW6Lvn4l"
      },
      "source": [
        "sum1 = torch.sum(z, axis=0)\n",
        "sum2 = torch.sum(z, axis=1)\n",
        "sum3 = torch.sum(z, axis=-1)\n",
        "print(sum1, sum1.shape)\n",
        "print(sum2, sum2.shape)\n",
        "print(sum3, sum3.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G9rJX56vzn_"
      },
      "source": [
        "a = torch.arange(24).reshape(4, 6)\n",
        "b = a.clone().detach()\n",
        "print(a, a.shape)\n",
        "print(b, b.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpEX2hRVwAlN"
      },
      "source": [
        "c = torch.cat([a, b], axis=0)\n",
        "print(c, c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsl2iOLJwNxs"
      },
      "source": [
        "c = torch.cat([a, b], axis=1)\n",
        "print(c, c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew4pfEHnwXH2"
      },
      "source": [
        "# **3. Pytorchë¡œ êµ¬í˜„í•œ ì†ê¸€ì”¨**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbW9CHg6wd5G"
      },
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOFfA404w2tE"
      },
      "source": [
        "## MNIST Data down\n",
        "\n",
        "# ê³µê°œ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ë°ì´í„°ë¥¼ ë‚´ë ¤ë°›ìŒ\n",
        "training_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# ê³µê°œ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ë°ì´í„°ë¥¼ ë‚´ë ¤ë°›ìŒ\n",
        "test_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q0xnuLqxWVn"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# ë°ì´í„°ë¡œë”ë¥¼ ìƒì„±, í…ì„œì—ì„œëŠ” ë°ì´í„°ì…‹\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print('Shape of X [N, C, H, W]: ', X.shape)\n",
        "  print('Shape of y: ', y.shape, y.dtype)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfkznT_PyUql"
      },
      "source": [
        "# í•™ìŠµì— ì‚¬ìš©í•  CPUë‚˜ GPUì¥ì¹˜ë¥¼ ì–»ìŒ\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# ëª¨ë¸ì„ ì •ì˜\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(128, 10)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "  \n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsfJn2P6yuC9"
      },
      "source": [
        "# Loss í•¨ìˆ˜ì™€ Optimizer ì„¤ì •\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zehiXsxp1Ahc"
      },
      "source": [
        "# Trainingì„ ìœ„í•œ í•¨ìˆ˜\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # ì˜ˆì¸¡ ì˜¤ë¥˜ ê³„ì‚°\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # ì—­ì „íŒŒ\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27FaHYsP1_ol"
      },
      "source": [
        "# Testë¥¼ ìœ„í•œ í•¨ìˆ˜\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  print(size)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W86Q3XPoD7k"
      },
      "source": [
        "epochs = 10 # 10 epochs ë™ì•ˆ ëŒë©´ì„œ training 1ë²ˆ, test 1ë²ˆ ì§„í–‰í•¨\n",
        "for t in range(epochs):\n",
        "  print(f'Epoch {t+1}\\-------------------------------')\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print('ë!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BUyYyHXqNn9"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('file : \"{name}, length : {length}bytes'. format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siCptN_0rjAu"
      },
      "source": [
        "# image fileì˜ ê²½ë¡œ ì„¤ì •\n",
        "cur_dir = os.getcwd()\n",
        "img_path = os.path.join(cur_dir, 'image2.png')\n",
        "# image file ì½ê¸°\n",
        "cur_img = Image.open(img_path)\n",
        "# 28*28ë¡œ resize\n",
        "cur_img = cur_img.resize((28, 28))\n",
        "image = np.asarray(cur_img)\n",
        "\n",
        "try:\n",
        "  image = np.mean(image, axis=2)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# uploadí•œ imagesëŠ” í° ë°°ê²½ì— ê²€ì€ ê¸€ì”¨ë¡œ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ MNIST dataì™€ ê°™ì´ ê²€ì€ ë°°ê²½ì— í° ê¸€ì”¨ë¡œ ë³€ê²½\n",
        "image = np.abs(255-image)\n",
        "# MNISTì™€ ë™ì¼í•˜ê²Œ data preprocessing(255ë¡œ ë‚˜ëˆ”)\n",
        "image = image.astype(np.float32)/255.\n",
        "# í™”ë©´ì— ì¶œë ¥í•˜ì—¬ í™•ì¸\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOh5uIbrtluC"
      },
      "source": [
        "image = torch.as_tensor(image).to(device).reshape(1,1,28,28)\n",
        "model.eval()\n",
        "predict = model(image)\n",
        "print('modelì´ ì˜ˆì¸¡í•œ ê°’ì€ {} ì…ë‹ˆë‹¤.'.format(predict.argmax(1).item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqyT5YNyt3Vc"
      },
      "source": [
        "4. Dataset / Dataloader\n",
        "* dataë¥¼ ì²˜ë¦¬í•˜ì—¬ modelì— ê³µê¸‰í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ Pytorchì—ì„œëŠ” datasetê³¼ dataloaderë¥¼ ì œê³µ\n",
        "* datasetì€ dataì™€ labelì„ ì €ì¥í•˜ê³ , dataloaderì„ modelì— ê³µê¸‰í•  ìˆ˜ ìˆë„ë¡ iterable ê°ì²´ë¡œ ê°ì‹¸ì¤Œ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PB6HSaGuUJN"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Ia_xQPxVLW"
      },
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor() # í…ì„œë¡œ ë°”ê¿”ì£¼ë©´ì„œ ì´ë¯¸ì§€ í”½ì…€ì„ 0~1ì‚¬ì´ë¡œ ë°”ê¾¸ì–´ì¤Œ\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oo2BzEXx9cG"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1, )).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img.squeeze(), cmap='gray') # squeeze ì±„ë„ì„ ì—†ì• ì¤Œ - ì•ì— batch(1)ê°€ ë“¤ì–´ê°€ê³  ê·¸ë‹¤ìŒ 28*28 ì´ ë“¤ì–´ê°€ëŠ”ë° ì•ì— ì“¸ëª¨ì—†ëŠ” batchë¥¼ ì œê±°í•¨\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmTcBcO0zq_1"
      },
      "source": [
        "# DataLoader ë§Œë“¤ê¸° -> ë°ì´í„°ë¥¼ ê³µê¸‰í•´ì£¼ëŠ” ê²ƒ\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU5KCr0U1TUm"
      },
      "source": [
        "# DataLoaderë¥¼ í†µí•´ ë°˜ë³µí•˜ê¸°(iterate)\n",
        "# ì´ë¯¸ì§€ì™€ ì •ë‹µ(label)ì„ í‘œì‹œí•¨\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f'Feature batch shape: {train_features.size()}')\n",
        "print(f'Labels batch shape: {train_labels.size()}')\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "print(f'Label: {label}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFMl08Fk1hxd"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQMzxnKw3U2E"
      },
      "source": [
        "# device ì„¤ì •\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3x2_ew3dzF"
      },
      "source": [
        "### **Model class ë§Œë“¤ê¸°**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF7Rh57L3jr1"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(128, 10) # denceì™€ ê°™ì€ ê²ƒ\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnMx2rJr5vOw"
      },
      "source": [
        "# Model instance ìƒì„±, device ì„¤ì •\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWmGbanC6K3k"
      },
      "source": [
        "# ê°€ìƒì˜ dataë¥¼ ë§Œë“¤ì–´ì„œ ì˜ˆì¸¡í•´ë³´ê¸°\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1g7nd9-6zNb"
      },
      "source": [
        "### **Training / Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF9K4B657d-M"
      },
      "source": [
        "### **Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8pyfABp7iFD"
      },
      "source": [
        "# ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì´ˆê¸°í™”\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO824usc7uBK"
      },
      "source": [
        "### **Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDht0kY670BM"
      },
      "source": [
        "learning_rate = 1e-3 \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyidJv5U8KkL"
      },
      "source": [
        "### **Training / Validation(Test) Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq3W1Rvn8Rrw"
      },
      "source": [
        "# Trainingì„ ìœ„í•œ í•¨ìˆ˜\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # ì˜ˆì¸¡(prediction)ê³¼ ì†ì‹¤(loss) ê³„ì‚°\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # ì—­ì „íŒŒ\n",
        "    # gradientê°’ë“¤ì„ backwardë¥¼ í•´ì¤„ ë•Œ ê³„ì† ê°’ì„ ë”í•´ì£¼ê¸° ë•Œë¬¸ì—\n",
        "    # loss.backward()ë¥¼ í˜¸ì¶œ í•  ë•Œ ì´ˆê¸°ì„¤ì •ì„ ë§¤ë²ˆ ë”í•´ì£¼ë¯€ë¡œ\n",
        "    # í•œë²ˆì˜ í•™ìŠµì´ ëë‚˜ë©´ ê°’ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™” í•´ì•¼ í•¨\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # ì—­ì „íŒŒê°€ ì¼ì–´ë‚¨\n",
        "    optimizer.step() # ì—…ë°ì´íŠ¸ë¨\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "# Testë¥¼ ìœ„í•œ í•¨ìˆ˜\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad(): # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3AOzb_5DY4S"
      },
      "source": [
        "# í•™ìŠµ ì§„í–‰í•˜ê¸°\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n--------------------------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "print('ì™„ë£Œ!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-rLMp5UEVhn"
      },
      "source": [
        "### **Model ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ê¸°**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2WhLwVOFB_a"
      },
      "source": [
        "# í•™ìŠµëœ model parameter ì €ì¥\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b90-QJPeFaHP"
      },
      "source": [
        "# ìƒˆ model instanceë¥¼ ìƒì„±, device ì„¤ì •\n",
        "model2 = NeuralNetwork().to(device)\n",
        "print(model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_1FQxHeFi14"
      },
      "source": [
        "# test\n",
        "model2.eval() # trainingì„ í•˜ì§€ ì•ŠìŒ\n",
        "test_loop(test_dataloader, model2, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2vRgZddFtjP"
      },
      "source": [
        "# ì €ì¥í•œ parameter ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model2.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHscbZ8TF6r3"
      },
      "source": [
        "# test\n",
        "model2.eval() # trainingì„ í•˜ì§€ ì•ŠìŒ\n",
        "test_loop(test_dataloader, model2, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOQjs2NnF8tv"
      },
      "source": [
        "# ì €ì¥í•˜ê¸°\n",
        "torch.save(model, 'model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQhErZIxHItH"
      },
      "source": [
        "# ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model3 = torch.load('model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFbEvWqcHLy4"
      },
      "source": [
        "# test\n",
        "model3.eval() # trainingì„ í•˜ì§€ ì•ŠìŒ\n",
        "test_loop(test_dataloader, model2, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q8FDaVdHOev"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}