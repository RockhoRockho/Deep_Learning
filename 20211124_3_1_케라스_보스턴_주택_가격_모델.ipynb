{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20211124_3.1 케라스 보스턴 주택 가격 모델.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RockhoRockho/Deep_Learning_Tensorflow/blob/main/20211124_3_1_%EC%BC%80%EB%9D%BC%EC%8A%A4_%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A3%BC%ED%83%9D_%EA%B0%80%EA%B2%A9_%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj-RA7rQLSC4"
      },
      "source": [
        "# 케라스 보스턴 주택 가격 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1rSC60ILf0U"
      },
      "source": [
        "### modules import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYcVLNsmFR_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbRqQY1aMMTU"
      },
      "source": [
        "### 데이터 로드\n",
        "- 데이터의 수가 상당히 적기 때문에 테스트 데이터의 비율을 20%로 지정\n",
        "\n",
        "- 13개의 특성을 가짐\n",
        "\n",
        "- 각각의 특성이 모두 다른 스케일, 즉 단위가 모두 다름\n",
        "  - 범죄율: 0~1 사이의 값\n",
        "  - 방의 개수 3~9 사이의 값\n",
        "\n",
        "- 정답 레이블은 주택 가격의 중간가격($1000 단위)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWHBrPVTMGyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d42848-9c2f-4129-a82e-60f8921e4d66"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2,\n",
        "                                                           seed=111)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCTcnMT6Mgx9"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdisxCBbMbRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd7e7b4-d0d0-41a8-bd95-4bcc118710e9"
      },
      "source": [
        "print(\"학습 데이터: {}\\t레이블: {}\".format(x_train_full.shape, y_train_full.shape))\n",
        "print(\"테스트 데이터: {}\\t레이블: {}\".format(x_test.shape, y_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjEoDJ6fM4I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dabb80b-f3c2-468e-f025-fb82811213f0"
      },
      "source": [
        "print(x_train_full[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.8750e-02 2.8000e+01 1.5040e+01 0.0000e+00 4.6400e-01 6.2110e+00\n",
            " 2.8900e+01 3.6659e+00 4.0000e+00 2.7000e+02 1.8200e+01 3.9633e+02\n",
            " 6.2100e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-V0pQdbNSso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e624bf70-b90a-43ad-dd8f-53e01a5598f1"
      },
      "source": [
        "print(y_train_full[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ZK_dJdOlCu"
      },
      "source": [
        "### 데이터 전처리\n",
        "- Standardization\n",
        "\n",
        "- 특성의 단위가 모두 다르기 때문에 **동일한 범위로 조정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjRcDM_CNV--"
      },
      "source": [
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full, axis=0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=111)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1fl37t9PR0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6276432-ec98-495e-f40f-e71d24c545f2"
      },
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train.shape, y_train.shape))\n",
        "print('검증 데이터: {}\\t레이블: {}'.format(x_val.shape, y_val.shape))\n",
        "print('테스트 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "학습 데이터: (282, 13)\t레이블: (282,)\n",
            "검증 데이터: (122, 13)\t레이블: (122,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcwvMqdPynu"
      },
      "source": [
        "### 모델 구성\n",
        "- 학습 데이터가 매우 적은 경우에 모델의 깊이를 깊게 할수록  \n",
        "  과대적합(Overfitting)이 일어날 확률이 높음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P7pAnqUPcCf"
      },
      "source": [
        "model = Sequential([Dense(100, activation='relu', input_shape=(13, ), name='dense1'),\n",
        "                    Dense(64, activation='relu', name='dense2'),\n",
        "                    Dense(32, activation='relu', name='dense3'),\n",
        "                    Dense(1, name='output')])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRi6Vd8WQYyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5340fde-b8a7-46d5-9901-364185ea382e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense1 (Dense)              (None, 100)               1400      \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 64)                6464      \n",
            "                                                                 \n",
            " dense3 (Dense)              (None, 32)                2080      \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dFvQRGQalM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "823222f9-6562-4203-cce3-ce0101834650"
      },
      "source": [
        "plot_model(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m05yRQmQmFA"
      },
      "source": [
        "### 모델 컴파일(compile)\n",
        "\n",
        "- 회귀 문제에서는 주로 평균제곱오차(MSE, Mean Squared Error)를 손실함수로,  \n",
        "  평균절대오차(MAE, Mean Absolute Error)를 평가지표로 많이 사용!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z2IMfH3QkGv"
      },
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer=Adam(learning_rate=1e-2),\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YhN4fzmRQpY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGA9gPIERPxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db90b108-f836-459f-d8fe-9d9ce658a761"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=300,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 32ms/step - loss: 285.1867 - mae: 14.0728 - val_loss: 132.4552 - val_mae: 9.1088\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.9879 - mae: 5.9217 - val_loss: 31.4357 - val_mae: 4.4588\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 33.7112 - mae: 4.2293 - val_loss: 22.2756 - val_mae: 3.6017\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 21.5946 - mae: 3.4391 - val_loss: 13.9826 - val_mae: 2.9190\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.3538 - mae: 2.8935 - val_loss: 11.7222 - val_mae: 2.7147\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.6432 - mae: 2.5889 - val_loss: 10.9746 - val_mae: 2.5883\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6474 - mae: 2.4426 - val_loss: 9.1844 - val_mae: 2.3985\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.5111 - mae: 2.5104 - val_loss: 9.8295 - val_mae: 2.4060\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.3260 - mae: 2.3506 - val_loss: 8.1732 - val_mae: 2.2383\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.1600 - mae: 2.3898 - val_loss: 8.3317 - val_mae: 2.2944\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.3496 - mae: 2.3828 - val_loss: 9.6378 - val_mae: 2.3146\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.4039 - mae: 2.3526 - val_loss: 8.3838 - val_mae: 2.3106\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6115 - mae: 2.1968 - val_loss: 8.4296 - val_mae: 2.2763\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.5119 - mae: 2.1870 - val_loss: 9.0308 - val_mae: 2.4176\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5965 - mae: 2.0715 - val_loss: 8.1153 - val_mae: 2.2021\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6299 - mae: 2.1294 - val_loss: 8.3422 - val_mae: 2.2116\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7118 - mae: 2.1223 - val_loss: 10.9280 - val_mae: 2.6192\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6292 - mae: 2.3363 - val_loss: 8.8307 - val_mae: 2.3392\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1346 - mae: 2.0553 - val_loss: 7.6521 - val_mae: 2.1379\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1805 - mae: 1.8884 - val_loss: 9.4470 - val_mae: 2.3891\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6500 - mae: 2.0444 - val_loss: 7.8327 - val_mae: 2.1984\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3324 - mae: 1.9635 - val_loss: 9.3716 - val_mae: 2.4086\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6551 - mae: 2.0688 - val_loss: 8.8704 - val_mae: 2.2852\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0313 - mae: 1.9690 - val_loss: 9.1773 - val_mae: 2.4254\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1506 - mae: 1.9644 - val_loss: 8.1157 - val_mae: 2.1429\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9995 - mae: 1.9212 - val_loss: 9.4194 - val_mae: 2.4622\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6071 - mae: 1.9843 - val_loss: 8.7924 - val_mae: 2.2862\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9470 - mae: 1.8271 - val_loss: 8.2805 - val_mae: 2.2896\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2320 - mae: 1.7261 - val_loss: 7.5434 - val_mae: 2.1259\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6595 - mae: 1.6583 - val_loss: 8.4574 - val_mae: 2.1964\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4742 - mae: 1.5777 - val_loss: 8.6926 - val_mae: 2.2252\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1797 - mae: 1.5585 - val_loss: 9.6175 - val_mae: 2.3321\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4064 - mae: 1.5809 - val_loss: 8.7470 - val_mae: 2.2373\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.0264 - mae: 1.4871 - val_loss: 7.8325 - val_mae: 2.1457\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3660 - mae: 1.5660 - val_loss: 8.6906 - val_mae: 2.3365\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0568 - mae: 1.4903 - val_loss: 9.3205 - val_mae: 2.3140\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4697 - mae: 1.3946 - val_loss: 7.8765 - val_mae: 2.1642\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4703 - mae: 1.4268 - val_loss: 9.7034 - val_mae: 2.3743\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9810 - mae: 1.5144 - val_loss: 7.6057 - val_mae: 2.1645\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.0855 - mae: 1.5292 - val_loss: 9.7195 - val_mae: 2.3163\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7704 - mae: 1.7092 - val_loss: 12.7589 - val_mae: 2.6005\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1469 - mae: 1.9897 - val_loss: 11.4851 - val_mae: 2.5366\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3832 - mae: 1.8995 - val_loss: 10.5150 - val_mae: 2.2199\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.6403 - mae: 1.8278 - val_loss: 11.6891 - val_mae: 2.7003\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9706 - mae: 2.0062 - val_loss: 10.9527 - val_mae: 2.6598\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9352 - mae: 2.0565 - val_loss: 10.9728 - val_mae: 2.4597\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6340 - mae: 1.7637 - val_loss: 10.6500 - val_mae: 2.2776\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9029 - mae: 1.7343 - val_loss: 9.7199 - val_mae: 2.2909\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6841 - mae: 1.4417 - val_loss: 8.3943 - val_mae: 2.1820\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6243 - mae: 1.4191 - val_loss: 9.5704 - val_mae: 2.2698\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.2140 - mae: 1.3597 - val_loss: 10.2109 - val_mae: 2.3336\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2337 - mae: 1.3574 - val_loss: 10.0223 - val_mae: 2.3409\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9345 - mae: 1.2908 - val_loss: 8.4636 - val_mae: 2.1616\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7762 - mae: 1.2562 - val_loss: 10.6221 - val_mae: 2.3861\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.7874 - mae: 1.2341 - val_loss: 9.4739 - val_mae: 2.2995\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7726 - mae: 1.2528 - val_loss: 9.1207 - val_mae: 2.2733\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.9526 - mae: 1.3232 - val_loss: 10.6138 - val_mae: 2.3364\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.0177 - mae: 1.3129 - val_loss: 9.7659 - val_mae: 2.3190\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2876 - mae: 1.4053 - val_loss: 8.0994 - val_mae: 2.2082\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1536 - mae: 1.3663 - val_loss: 9.0439 - val_mae: 2.3575\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8511 - mae: 1.2581 - val_loss: 10.1549 - val_mae: 2.3143\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8784 - mae: 1.2726 - val_loss: 11.1536 - val_mae: 2.3458\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8733 - mae: 1.2645 - val_loss: 11.4263 - val_mae: 2.3517\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1126 - mae: 1.3010 - val_loss: 8.0232 - val_mae: 2.1640\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6214 - mae: 1.2361 - val_loss: 8.8786 - val_mae: 2.2941\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.8104 - mae: 1.2522 - val_loss: 9.7510 - val_mae: 2.4294\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3696 - mae: 1.4165 - val_loss: 9.6101 - val_mae: 2.2196\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9704 - mae: 1.3187 - val_loss: 9.5717 - val_mae: 2.3054\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.8853 - mae: 1.2607 - val_loss: 10.5536 - val_mae: 2.3544\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.4782 - mae: 1.1560 - val_loss: 8.9996 - val_mae: 2.2318\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6247 - mae: 1.1912 - val_loss: 9.0692 - val_mae: 2.2396\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7245 - mae: 1.2466 - val_loss: 13.2116 - val_mae: 2.7036\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7373 - mae: 1.4340 - val_loss: 10.7481 - val_mae: 2.4080\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.7300 - mae: 1.2438 - val_loss: 11.5931 - val_mae: 2.4290\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2021 - mae: 1.1033 - val_loss: 9.9672 - val_mae: 2.2671\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2769 - mae: 1.1490 - val_loss: 10.7951 - val_mae: 2.4438\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.4305 - mae: 1.1767 - val_loss: 11.8542 - val_mae: 2.6102\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8511 - mae: 1.3174 - val_loss: 12.7669 - val_mae: 2.5513\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.6837 - mae: 1.2436 - val_loss: 8.8326 - val_mae: 2.2590\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3604 - mae: 1.4099 - val_loss: 16.4926 - val_mae: 2.9441\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6746 - mae: 1.7955 - val_loss: 8.6653 - val_mae: 2.1521\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0628 - mae: 1.7276 - val_loss: 18.0027 - val_mae: 2.9864\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2843 - mae: 1.8752 - val_loss: 15.1713 - val_mae: 2.8038\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0373 - mae: 1.5227 - val_loss: 7.0178 - val_mae: 1.9777\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1167 - mae: 1.3482 - val_loss: 9.4219 - val_mae: 2.3205\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.2866 - mae: 1.3115 - val_loss: 9.6451 - val_mae: 2.2355\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4459 - mae: 1.1923 - val_loss: 9.2421 - val_mae: 2.3142\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2040 - mae: 1.1082 - val_loss: 9.8664 - val_mae: 2.2543\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2161 - mae: 1.1287 - val_loss: 8.5572 - val_mae: 2.1170\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8174 - mae: 1.2672 - val_loss: 10.1788 - val_mae: 2.3667\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6965 - mae: 1.2222 - val_loss: 8.8491 - val_mae: 2.1180\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.1412 - mae: 1.1044 - val_loss: 8.2296 - val_mae: 2.2248\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3710 - mae: 1.1341 - val_loss: 12.7051 - val_mae: 2.5838\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7269 - mae: 1.2266 - val_loss: 8.0841 - val_mae: 2.1124\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4937 - mae: 1.2193 - val_loss: 11.6250 - val_mae: 2.4151\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5528 - mae: 1.2250 - val_loss: 10.4961 - val_mae: 2.3719\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4382 - mae: 1.2543 - val_loss: 8.8269 - val_mae: 2.3024\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.6936 - mae: 1.2520 - val_loss: 10.7747 - val_mae: 2.4636\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4629 - mae: 1.4154 - val_loss: 9.2709 - val_mae: 2.2714\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6291 - mae: 1.2840 - val_loss: 12.4179 - val_mae: 2.5784\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6719 - mae: 1.2448 - val_loss: 9.8593 - val_mae: 2.3342\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2545 - mae: 1.1177 - val_loss: 8.9211 - val_mae: 2.3360\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6225 - mae: 1.2245 - val_loss: 12.5376 - val_mae: 2.5470\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.4938 - mae: 1.1771 - val_loss: 10.9494 - val_mae: 2.3913\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5889 - mae: 1.1486 - val_loss: 11.3389 - val_mae: 2.3862\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5434 - mae: 1.2228 - val_loss: 12.5750 - val_mae: 2.7382\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2656 - mae: 1.4481 - val_loss: 9.6689 - val_mae: 2.3499\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.0149 - mae: 1.0155 - val_loss: 9.4610 - val_mae: 2.2156\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6937 - mae: 0.9390 - val_loss: 10.1859 - val_mae: 2.2956\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4919 - mae: 0.8930 - val_loss: 8.9552 - val_mae: 2.1916\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5539 - mae: 0.9223 - val_loss: 9.9675 - val_mae: 2.3342\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5137 - mae: 0.8935 - val_loss: 9.6574 - val_mae: 2.2921\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3446 - mae: 0.8393 - val_loss: 10.2114 - val_mae: 2.2849\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5414 - mae: 0.9070 - val_loss: 10.3743 - val_mae: 2.3619\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3980 - mae: 0.8822 - val_loss: 7.9374 - val_mae: 2.1445\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6690 - mae: 0.9585 - val_loss: 10.7224 - val_mae: 2.4238\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6784 - mae: 0.9364 - val_loss: 11.0402 - val_mae: 2.3552\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5440 - mae: 0.9392 - val_loss: 9.8124 - val_mae: 2.2305\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8203 - mae: 1.0233 - val_loss: 10.6476 - val_mae: 2.4967\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1230 - mae: 1.0882 - val_loss: 9.7561 - val_mae: 2.3930\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7872 - mae: 1.0168 - val_loss: 9.2665 - val_mae: 2.1807\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8524 - mae: 1.0232 - val_loss: 10.7979 - val_mae: 2.4442\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9880 - mae: 1.0135 - val_loss: 11.9148 - val_mae: 2.5539\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5853 - mae: 0.9537 - val_loss: 9.7088 - val_mae: 2.2471\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4335 - mae: 0.8868 - val_loss: 12.1218 - val_mae: 2.4992\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3630 - mae: 0.8477 - val_loss: 8.6368 - val_mae: 2.2263\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3810 - mae: 0.8600 - val_loss: 11.1485 - val_mae: 2.4045\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2611 - mae: 0.8263 - val_loss: 9.6640 - val_mae: 2.2799\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3584 - mae: 0.8493 - val_loss: 9.7536 - val_mae: 2.3608\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8158 - mae: 1.0453 - val_loss: 9.5430 - val_mae: 2.3783\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8831 - mae: 1.0220 - val_loss: 11.2776 - val_mae: 2.4426\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2852 - mae: 0.8498 - val_loss: 10.9830 - val_mae: 2.3570\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4271 - mae: 0.8938 - val_loss: 9.9754 - val_mae: 2.4167\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3740 - mae: 0.8862 - val_loss: 9.1961 - val_mae: 2.2688\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0499 - mae: 0.7400 - val_loss: 10.4275 - val_mae: 2.3787\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0266 - mae: 0.7408 - val_loss: 10.8574 - val_mae: 2.4024\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0471 - mae: 0.7280 - val_loss: 10.5326 - val_mae: 2.3814\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.7397 - mae: 0.9582 - val_loss: 10.5359 - val_mae: 2.3571\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0975 - mae: 1.1183 - val_loss: 10.9314 - val_mae: 2.3901\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7240 - mae: 1.0040 - val_loss: 10.6000 - val_mae: 2.3540\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2295 - mae: 0.8422 - val_loss: 10.0529 - val_mae: 2.4008\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3771 - mae: 0.8872 - val_loss: 9.6779 - val_mae: 2.2838\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1896 - mae: 0.7896 - val_loss: 12.1079 - val_mae: 2.4334\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7549 - mae: 1.0289 - val_loss: 12.0467 - val_mae: 2.5788\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.8409 - mae: 1.0395 - val_loss: 11.1251 - val_mae: 2.4525\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5188 - mae: 0.9522 - val_loss: 9.4893 - val_mae: 2.2976\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3793 - mae: 0.8502 - val_loss: 10.1026 - val_mae: 2.3637\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.7475 - mae: 0.9759 - val_loss: 10.8199 - val_mae: 2.5397\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.6644 - mae: 1.0040 - val_loss: 9.4273 - val_mae: 2.2362\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5623 - mae: 0.9367 - val_loss: 9.7407 - val_mae: 2.2629\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2121 - mae: 0.8152 - val_loss: 11.0640 - val_mae: 2.5104\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5259 - mae: 0.9377 - val_loss: 9.2505 - val_mae: 2.2181\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4002 - mae: 0.8568 - val_loss: 10.7277 - val_mae: 2.4564\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3662 - mae: 0.8562 - val_loss: 10.9492 - val_mae: 2.3656\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3588 - mae: 0.8301 - val_loss: 9.9360 - val_mae: 2.3240\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4306 - mae: 0.8661 - val_loss: 11.2018 - val_mae: 2.4867\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.0081 - mae: 1.0753 - val_loss: 10.9778 - val_mae: 2.4793\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4599 - mae: 1.1919 - val_loss: 9.9372 - val_mae: 2.4297\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4747 - mae: 0.9201 - val_loss: 10.0480 - val_mae: 2.3854\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4989 - mae: 0.9269 - val_loss: 9.4613 - val_mae: 2.3166\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.7398 - mae: 0.9795 - val_loss: 12.6307 - val_mae: 2.6166\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.7932 - mae: 1.0112 - val_loss: 10.4370 - val_mae: 2.3385\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3210 - mae: 0.8798 - val_loss: 12.7214 - val_mae: 2.5649\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3302 - mae: 0.8794 - val_loss: 10.0744 - val_mae: 2.3405\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3070 - mae: 0.8520 - val_loss: 9.3796 - val_mae: 2.2691\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1169 - mae: 0.7383 - val_loss: 10.1817 - val_mae: 2.3769\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2423 - mae: 0.7854 - val_loss: 11.0747 - val_mae: 2.3780\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3840 - mae: 0.8813 - val_loss: 9.5057 - val_mae: 2.2866\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0783 - mae: 0.7499 - val_loss: 10.6876 - val_mae: 2.3470\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9413 - mae: 0.7018 - val_loss: 9.5088 - val_mae: 2.3195\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5867 - mae: 0.8870 - val_loss: 10.0106 - val_mae: 2.3551\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7697 - mae: 0.9844 - val_loss: 10.2461 - val_mae: 2.4242\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5869 - mae: 0.9339 - val_loss: 11.6168 - val_mae: 2.4435\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4901 - mae: 0.9117 - val_loss: 8.9653 - val_mae: 2.2312\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3555 - mae: 0.8847 - val_loss: 11.6661 - val_mae: 2.5684\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6071 - mae: 0.9911 - val_loss: 10.3792 - val_mae: 2.4167\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4475 - mae: 0.9171 - val_loss: 11.1980 - val_mae: 2.5358\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3127 - mae: 1.4522 - val_loss: 10.9151 - val_mae: 2.5428\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7468 - mae: 1.7445 - val_loss: 11.7104 - val_mae: 2.4608\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9645 - mae: 1.8956 - val_loss: 10.7506 - val_mae: 2.4234\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9447 - mae: 1.5725 - val_loss: 15.9121 - val_mae: 2.9115\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3928 - mae: 1.3862 - val_loss: 10.6792 - val_mae: 2.3245\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2981 - mae: 1.1573 - val_loss: 10.2142 - val_mae: 2.2850\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0435 - mae: 1.0822 - val_loss: 8.8693 - val_mae: 2.1400\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6350 - mae: 0.9617 - val_loss: 10.5439 - val_mae: 2.3609\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2520 - mae: 0.8327 - val_loss: 9.1201 - val_mae: 2.2111\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2987 - mae: 0.8279 - val_loss: 10.2322 - val_mae: 2.3426\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5699 - mae: 1.0004 - val_loss: 10.6541 - val_mae: 2.4189\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6682 - mae: 1.0024 - val_loss: 8.8652 - val_mae: 2.1586\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5471 - mae: 0.9419 - val_loss: 10.7194 - val_mae: 2.3728\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8017 - mae: 1.0225 - val_loss: 10.4114 - val_mae: 2.3515\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5541 - mae: 0.9558 - val_loss: 9.6925 - val_mae: 2.2998\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.3170 - mae: 0.8937 - val_loss: 10.7856 - val_mae: 2.4505\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7680 - mae: 1.0410 - val_loss: 9.3802 - val_mae: 2.2492\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4436 - mae: 0.9178 - val_loss: 9.1556 - val_mae: 2.3096\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.7516 - mae: 0.9563 - val_loss: 12.9305 - val_mae: 2.5216\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7580 - mae: 0.9745 - val_loss: 11.8557 - val_mae: 2.5022\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4734 - mae: 0.8680 - val_loss: 11.5995 - val_mae: 2.4463\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2846 - mae: 0.8268 - val_loss: 9.0191 - val_mae: 2.1870\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0175 - mae: 0.7534 - val_loss: 9.2640 - val_mae: 2.2995\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0219 - mae: 0.7338 - val_loss: 8.8760 - val_mae: 2.1783\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1233 - mae: 0.7693 - val_loss: 10.8026 - val_mae: 2.3474\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1768 - mae: 0.8107 - val_loss: 11.0606 - val_mae: 2.3620\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3089 - mae: 0.8619 - val_loss: 10.0156 - val_mae: 2.3377\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2739 - mae: 0.8504 - val_loss: 10.2511 - val_mae: 2.3541\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0848 - mae: 0.7776 - val_loss: 9.2682 - val_mae: 2.3449\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2270 - mae: 0.8003 - val_loss: 8.8740 - val_mae: 2.1818\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0863 - mae: 0.7238 - val_loss: 9.8060 - val_mae: 2.2914\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0142 - mae: 0.7374 - val_loss: 9.8945 - val_mae: 2.2361\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2503 - mae: 0.8493 - val_loss: 12.2369 - val_mae: 2.4999\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3627 - mae: 0.8975 - val_loss: 9.5342 - val_mae: 2.2472\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4833 - mae: 0.9295 - val_loss: 9.6474 - val_mae: 2.2875\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5228 - mae: 0.8958 - val_loss: 9.6644 - val_mae: 2.3945\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1062 - mae: 0.7886 - val_loss: 9.7916 - val_mae: 2.3218\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1600 - mae: 0.8002 - val_loss: 8.7234 - val_mae: 2.1570\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.9681 - mae: 0.7031 - val_loss: 11.6918 - val_mae: 2.4611\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8160 - mae: 0.6674 - val_loss: 9.6913 - val_mae: 2.2835\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8077 - mae: 0.6166 - val_loss: 9.3606 - val_mae: 2.2684\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8727 - mae: 0.6867 - val_loss: 10.9214 - val_mae: 2.3801\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9560 - mae: 0.7308 - val_loss: 8.7016 - val_mae: 2.2534\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9602 - mae: 0.7224 - val_loss: 10.7165 - val_mae: 2.3939\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0455 - mae: 0.7381 - val_loss: 10.5206 - val_mae: 2.3782\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7933 - mae: 0.6535 - val_loss: 8.6998 - val_mae: 2.1804\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0297 - mae: 0.7118 - val_loss: 10.7877 - val_mae: 2.4016\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0886 - mae: 0.7863 - val_loss: 8.8354 - val_mae: 2.2296\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8502 - mae: 0.6593 - val_loss: 10.7717 - val_mae: 2.3904\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9427 - mae: 0.7239 - val_loss: 9.7412 - val_mae: 2.3013\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1126 - mae: 0.7599 - val_loss: 10.8384 - val_mae: 2.3899\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4174 - mae: 0.8286 - val_loss: 9.5101 - val_mae: 2.2712\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0393 - mae: 0.7468 - val_loss: 10.1467 - val_mae: 2.2824\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2406 - mae: 0.8697 - val_loss: 10.5526 - val_mae: 2.4135\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.8443 - mae: 1.0645 - val_loss: 10.7284 - val_mae: 2.4604\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2981 - mae: 1.1224 - val_loss: 8.4632 - val_mae: 2.1513\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0037 - mae: 1.0397 - val_loss: 13.1786 - val_mae: 2.7351\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.8055 - mae: 1.0163 - val_loss: 12.2039 - val_mae: 2.4805\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2883 - mae: 0.8439 - val_loss: 8.4375 - val_mae: 2.1514\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1386 - mae: 0.7996 - val_loss: 11.0126 - val_mae: 2.4297\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0556 - mae: 0.7688 - val_loss: 9.4046 - val_mae: 2.2463\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2066 - mae: 0.8404 - val_loss: 10.5528 - val_mae: 2.3951\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0765 - mae: 0.7811 - val_loss: 10.4978 - val_mae: 2.3204\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0182 - mae: 0.7397 - val_loss: 9.3711 - val_mae: 2.2672\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9476 - mae: 0.7209 - val_loss: 9.2484 - val_mae: 2.2634\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8595 - mae: 0.6899 - val_loss: 10.3903 - val_mae: 2.3179\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0318 - mae: 0.7246 - val_loss: 10.3171 - val_mae: 2.3780\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1433 - mae: 0.7960 - val_loss: 10.4403 - val_mae: 2.3495\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8730 - mae: 0.7032 - val_loss: 9.4985 - val_mae: 2.2459\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8594 - mae: 0.6827 - val_loss: 9.7091 - val_mae: 2.2851\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6235 - mae: 0.5650 - val_loss: 9.8446 - val_mae: 2.3117\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5621 - mae: 0.5202 - val_loss: 9.5603 - val_mae: 2.2510\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6734 - mae: 0.5604 - val_loss: 10.1337 - val_mae: 2.2663\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8455 - mae: 0.6600 - val_loss: 11.4733 - val_mae: 2.5590\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9500 - mae: 1.0973 - val_loss: 11.4610 - val_mae: 2.4957\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5128 - mae: 0.9277 - val_loss: 9.8833 - val_mae: 2.3498\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9655 - mae: 0.7511 - val_loss: 9.7345 - val_mae: 2.2807\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1656 - mae: 0.8538 - val_loss: 9.9561 - val_mae: 2.3094\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5365 - mae: 0.9805 - val_loss: 9.9729 - val_mae: 2.2807\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.0155 - mae: 1.0376 - val_loss: 10.9330 - val_mae: 2.4554\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3739 - mae: 0.8982 - val_loss: 10.0242 - val_mae: 2.3017\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1451 - mae: 0.7868 - val_loss: 9.4470 - val_mae: 2.2403\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8348 - mae: 0.6545 - val_loss: 10.1351 - val_mae: 2.3291\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0319 - mae: 0.7478 - val_loss: 10.4247 - val_mae: 2.2773\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9441 - mae: 0.7081 - val_loss: 10.7744 - val_mae: 2.3746\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9039 - mae: 0.7127 - val_loss: 10.8067 - val_mae: 2.3611\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1129 - mae: 0.8119 - val_loss: 8.9594 - val_mae: 2.2456\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8974 - mae: 0.7159 - val_loss: 9.4089 - val_mae: 2.3697\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8840 - mae: 0.6730 - val_loss: 11.0078 - val_mae: 2.4061\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6863 - mae: 0.5991 - val_loss: 8.8959 - val_mae: 2.1797\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7785 - mae: 0.6241 - val_loss: 13.3159 - val_mae: 2.5297\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9029 - mae: 0.6919 - val_loss: 10.1606 - val_mae: 2.2992\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0037 - mae: 0.7185 - val_loss: 11.5526 - val_mae: 2.4340\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0137 - mae: 0.7407 - val_loss: 9.2510 - val_mae: 2.2267\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1038 - mae: 0.7776 - val_loss: 10.0266 - val_mae: 2.4159\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0483 - mae: 0.7718 - val_loss: 10.3152 - val_mae: 2.3859\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9002 - mae: 0.7080 - val_loss: 9.7211 - val_mae: 2.3239\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6879 - mae: 0.6378 - val_loss: 9.1705 - val_mae: 2.2293\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7905 - mae: 0.6596 - val_loss: 10.7186 - val_mae: 2.4364\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6073 - mae: 0.5533 - val_loss: 8.6500 - val_mae: 2.1555\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5499 - mae: 0.5317 - val_loss: 10.5796 - val_mae: 2.3548\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5320 - mae: 0.5090 - val_loss: 9.6521 - val_mae: 2.2238\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5584 - mae: 0.5129 - val_loss: 11.2702 - val_mae: 2.3869\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5731 - mae: 0.5576 - val_loss: 10.0860 - val_mae: 2.2883\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5867 - mae: 0.5728 - val_loss: 9.9770 - val_mae: 2.3622\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7993 - mae: 0.6690 - val_loss: 10.7938 - val_mae: 2.3192\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0520 - mae: 0.7400 - val_loss: 9.9394 - val_mae: 2.3093\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1740 - mae: 0.8043 - val_loss: 11.7895 - val_mae: 2.6562\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9706 - mae: 0.7378 - val_loss: 9.7993 - val_mae: 2.2863\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7292 - mae: 0.6329 - val_loss: 10.0044 - val_mae: 2.3433\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7442 - mae: 0.6673 - val_loss: 10.2636 - val_mae: 2.2537\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8125 - mae: 0.6970 - val_loss: 10.3874 - val_mae: 2.3947\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8408 - mae: 0.6971 - val_loss: 9.6421 - val_mae: 2.2853\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7221 - mae: 0.6301 - val_loss: 10.2480 - val_mae: 2.3206\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7118 - mae: 0.6158 - val_loss: 9.9742 - val_mae: 2.2978\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7565 - mae: 0.6485 - val_loss: 9.6521 - val_mae: 2.3005\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7145 - mae: 0.6391 - val_loss: 9.6444 - val_mae: 2.3451\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6601 - mae: 0.6053 - val_loss: 11.0317 - val_mae: 2.3515\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7856 - mae: 0.6784 - val_loss: 9.5353 - val_mae: 2.3029\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6704 - mae: 0.6081 - val_loss: 10.2397 - val_mae: 2.2879\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6880 - mae: 0.5960 - val_loss: 10.1665 - val_mae: 2.3081\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6722 - mae: 0.5899 - val_loss: 10.6690 - val_mae: 2.3459\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6243 - mae: 0.5639 - val_loss: 10.1682 - val_mae: 2.2997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1erMMEoeR0rB"
      },
      "source": [
        "### 모델 평가 \n",
        "- `evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0n0SaZRbD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99dd6e47-d06e-4977-c0d0-77ed10e69d84"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step - loss: 14.6935 - mae: 2.5611\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.693495750427246, 2.561081886291504]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl98Ql_8nvf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d918aa-4019-41ef-841f-4d2c2fe140e7"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOgcoBclnsJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "73a5e20f-d607-47fd-c44c-c212f938eb05"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, loss, color='blue', label='train_loss')\n",
        "ax1.plot(epochs, val_loss, color='red', label='val_loss')\n",
        "ax1.set_title('Train and Validation Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "mae = history_dict['mae']\n",
        "val_mae= history_dict['val_mae']\n",
        "\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, loss, color='blue', label='train_mae')\n",
        "ax2.plot(epochs, val_loss, color='red', label='val_mae')\n",
        "ax2.set_title('Train and Validation MAE')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('MAE')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtICFsIvVpF2"
      },
      "source": [
        "### K-Fold 교차 검증\n",
        "\n",
        "- 데이터셋의 크기가 매우 작은 경우에  \n",
        "  [훈련, 검증, 테스트] 데이터로 나누게 되면 과소적합이 일어날 확률이 높음\n",
        "\n",
        "- 이를 해결하기 위해 K-Fold 교차 검증 실행\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://scikit-learn.org/stable/modules/cross_validation.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNUN6mwWSDO"
      },
      "source": [
        "### 모델 재구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIFRNBlYWzBc"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60EvVZ9qR5v6"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2,\n",
        "                                                           seed=111)\n",
        "\n",
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full, axis=0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HiJbnWrWkXY"
      },
      "source": [
        "k = 3\n",
        "\n",
        "kfold = KFold(n_splits=k, random_state=123, shuffle=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3uTP6oXDzr"
      },
      "source": [
        "def build_model():\n",
        "  input = Input(shape=(13, ), name='input')\n",
        "  hidden1 = Dense(100, activation='relu', name='dense1')(input)\n",
        "  hidden2 = Dense(64, activation='relu', name='dense2')(hidden1)\n",
        "  hidden3 = Dense(32, activation='relu', name='dense3')(hidden2)\n",
        "  output = Dense(1, name='output')(hidden3)\n",
        "\n",
        "  model = Model(inputs=[input], outputs=output)\n",
        "\n",
        "  model.compile(loss = 'mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMCmLyLYI2l"
      },
      "source": [
        "mae_list = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_0YHP-YUHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4019ebe4-b4b4-4615-b3ad-b6f255203a9f"
      },
      "source": [
        "for train_idx, val_idx in kfold.split(x_train):\n",
        "  x_train_fold, x_val_fold = x_train[train_idx], x_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train_full[train_idx], y_train_full[val_idx]\n",
        "\n",
        "  model = build_model()\n",
        "\n",
        "  model.fit(x_train_fold, y_train_fold, epochs=300,\n",
        "            validation_data=(x_val_fold, y_val_fold))\n",
        "  \n",
        "  _, test_mae = model.evaluate(x_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 42ms/step - loss: 585.2155 - mae: 22.2629 - val_loss: 602.4570 - val_mae: 22.5648\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 552.4590 - mae: 21.5254 - val_loss: 564.2101 - val_mae: 21.6679\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 509.2601 - mae: 20.4837 - val_loss: 513.1047 - val_mae: 20.4046\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 453.4613 - mae: 19.0507 - val_loss: 445.9886 - val_mae: 18.5960\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 379.7284 - mae: 16.9768 - val_loss: 364.6409 - val_mae: 16.2038\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 297.3375 - mae: 14.2945 - val_loss: 275.5331 - val_mae: 13.5300\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 210.7303 - mae: 11.2431 - val_loss: 201.4791 - val_mae: 11.1194\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 155.2777 - mae: 9.1409 - val_loss: 165.5030 - val_mae: 9.7256\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 144.0784 - mae: 9.0784 - val_loss: 156.2243 - val_mae: 9.4802\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 135.5391 - mae: 8.9244 - val_loss: 137.5557 - val_mae: 8.7823\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 118.3878 - mae: 8.1535 - val_loss: 124.5211 - val_mae: 8.2998\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 109.9553 - mae: 7.7143 - val_loss: 116.8135 - val_mae: 7.9739\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 103.8534 - mae: 7.4086 - val_loss: 109.8310 - val_mae: 7.7182\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 100.0241 - mae: 7.2654 - val_loss: 104.3047 - val_mae: 7.5085\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 97.6488 - mae: 7.2287 - val_loss: 100.3278 - val_mae: 7.3823\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 95.7262 - mae: 7.1767 - val_loss: 97.5929 - val_mae: 7.2964\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 94.8644 - mae: 7.1759 - val_loss: 96.0741 - val_mae: 7.2492\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.7793 - mae: 7.1851 - val_loss: 94.8358 - val_mae: 7.2073\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 92.7913 - mae: 7.1041 - val_loss: 93.8981 - val_mae: 7.1355\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 91.7072 - mae: 7.0050 - val_loss: 93.2450 - val_mae: 7.1100\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.8225 - mae: 6.9605 - val_loss: 92.9868 - val_mae: 7.0903\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 90.2855 - mae: 6.9543 - val_loss: 93.0847 - val_mae: 7.0835\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 89.1913 - mae: 6.9188 - val_loss: 92.6696 - val_mae: 7.0596\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 88.6143 - mae: 6.8909 - val_loss: 92.1354 - val_mae: 7.0480\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 88.0109 - mae: 6.8878 - val_loss: 91.5111 - val_mae: 7.0429\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 87.4822 - mae: 6.8880 - val_loss: 91.1009 - val_mae: 7.0286\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 86.9629 - mae: 6.8560 - val_loss: 90.8837 - val_mae: 7.0039\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.5220 - mae: 6.7993 - val_loss: 91.6810 - val_mae: 6.9926\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 86.0073 - mae: 6.7488 - val_loss: 91.1783 - val_mae: 6.9924\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.4083 - mae: 6.7601 - val_loss: 90.6022 - val_mae: 6.9801\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 84.9080 - mae: 6.7475 - val_loss: 91.0088 - val_mae: 6.9630\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.4846 - mae: 6.7222 - val_loss: 90.1472 - val_mae: 6.9655\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 83.9820 - mae: 6.6907 - val_loss: 90.1239 - val_mae: 6.9497\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 83.2307 - mae: 6.6534 - val_loss: 90.2833 - val_mae: 6.9384\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 82.7209 - mae: 6.6337 - val_loss: 90.4518 - val_mae: 6.9305\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.5174 - mae: 6.6517 - val_loss: 90.2620 - val_mae: 6.9366\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.0300 - mae: 6.6518 - val_loss: 89.6410 - val_mae: 6.9262\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.4021 - mae: 6.6105 - val_loss: 89.2298 - val_mae: 6.8974\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 81.0804 - mae: 6.5657 - val_loss: 88.8719 - val_mae: 6.8908\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 80.8784 - mae: 6.5720 - val_loss: 88.8172 - val_mae: 6.8970\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 80.2862 - mae: 6.5226 - val_loss: 89.1150 - val_mae: 6.8893\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 79.6493 - mae: 6.4901 - val_loss: 89.3931 - val_mae: 6.8741\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 79.3045 - mae: 6.4902 - val_loss: 89.2939 - val_mae: 6.8710\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 79.4745 - mae: 6.5609 - val_loss: 89.0877 - val_mae: 6.8952\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 79.0512 - mae: 6.4945 - val_loss: 88.9246 - val_mae: 6.8487\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 78.0079 - mae: 6.4000 - val_loss: 88.9611 - val_mae: 6.8544\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 77.7251 - mae: 6.4069 - val_loss: 88.4419 - val_mae: 6.8511\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 77.6793 - mae: 6.4695 - val_loss: 87.9572 - val_mae: 6.8526\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 76.7705 - mae: 6.4182 - val_loss: 88.3583 - val_mae: 6.8387\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 76.5612 - mae: 6.3695 - val_loss: 89.2467 - val_mae: 6.8144\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 76.3143 - mae: 6.3312 - val_loss: 88.4826 - val_mae: 6.8254\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 75.5893 - mae: 6.3317 - val_loss: 88.7159 - val_mae: 6.8244\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 75.2148 - mae: 6.3236 - val_loss: 88.0974 - val_mae: 6.8252\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 75.0032 - mae: 6.3250 - val_loss: 88.3347 - val_mae: 6.8310\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 74.4352 - mae: 6.3098 - val_loss: 88.1646 - val_mae: 6.8149\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 73.9926 - mae: 6.2869 - val_loss: 88.8300 - val_mae: 6.8054\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 73.6057 - mae: 6.2567 - val_loss: 88.4779 - val_mae: 6.7974\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 73.1564 - mae: 6.2372 - val_loss: 88.4469 - val_mae: 6.7916\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 72.7861 - mae: 6.2154 - val_loss: 88.5487 - val_mae: 6.7840\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 72.2897 - mae: 6.2052 - val_loss: 88.5427 - val_mae: 6.8098\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 72.1193 - mae: 6.2106 - val_loss: 88.5896 - val_mae: 6.7819\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 71.5192 - mae: 6.1703 - val_loss: 89.0939 - val_mae: 6.7866\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 71.0552 - mae: 6.1734 - val_loss: 88.6190 - val_mae: 6.7992\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 70.8294 - mae: 6.1710 - val_loss: 88.5568 - val_mae: 6.8036\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 70.3861 - mae: 6.1594 - val_loss: 88.4739 - val_mae: 6.7750\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 69.6486 - mae: 6.1073 - val_loss: 88.3943 - val_mae: 6.7496\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 69.5600 - mae: 6.0742 - val_loss: 89.2315 - val_mae: 6.7468\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 68.9011 - mae: 6.0682 - val_loss: 88.0612 - val_mae: 6.7737\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 68.5704 - mae: 6.0946 - val_loss: 88.3491 - val_mae: 6.7853\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 68.0103 - mae: 6.0520 - val_loss: 88.5167 - val_mae: 6.7499\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 67.3922 - mae: 5.9870 - val_loss: 89.0377 - val_mae: 6.7306\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 67.3081 - mae: 5.9778 - val_loss: 88.9007 - val_mae: 6.7668\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 66.5876 - mae: 5.9900 - val_loss: 88.8972 - val_mae: 6.8071\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 66.9719 - mae: 6.0343 - val_loss: 89.9686 - val_mae: 6.7849\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 65.7750 - mae: 5.9170 - val_loss: 90.1983 - val_mae: 6.7532\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 65.4849 - mae: 5.8409 - val_loss: 89.4223 - val_mae: 6.7901\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 64.7831 - mae: 5.9196 - val_loss: 88.4866 - val_mae: 6.8230\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 64.5097 - mae: 5.9655 - val_loss: 89.1889 - val_mae: 6.7942\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 63.1445 - mae: 5.8136 - val_loss: 89.9844 - val_mae: 6.7443\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 63.0914 - mae: 5.7802 - val_loss: 89.8921 - val_mae: 6.7677\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 62.4431 - mae: 5.7458 - val_loss: 89.9906 - val_mae: 6.7814\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 62.3184 - mae: 5.8304 - val_loss: 89.2787 - val_mae: 6.8234\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 61.8279 - mae: 5.8195 - val_loss: 90.7649 - val_mae: 6.8070\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 61.1532 - mae: 5.7130 - val_loss: 90.7005 - val_mae: 6.7860\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 60.5333 - mae: 5.6189 - val_loss: 91.4342 - val_mae: 6.8479\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 59.7485 - mae: 5.6401 - val_loss: 90.5589 - val_mae: 6.8442\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 60.0516 - mae: 5.7473 - val_loss: 90.6935 - val_mae: 6.8428\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 59.7902 - mae: 5.6261 - val_loss: 91.9748 - val_mae: 6.8182\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 57.9390 - mae: 5.5406 - val_loss: 90.7445 - val_mae: 6.8524\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 57.9410 - mae: 5.6268 - val_loss: 91.1754 - val_mae: 6.8608\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 56.8388 - mae: 5.5193 - val_loss: 92.2341 - val_mae: 6.8295\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 57.4617 - mae: 5.5255 - val_loss: 93.1887 - val_mae: 6.8707\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 56.1803 - mae: 5.5076 - val_loss: 92.4505 - val_mae: 6.9373\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 55.9427 - mae: 5.4831 - val_loss: 92.6273 - val_mae: 6.9013\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 55.0563 - mae: 5.4283 - val_loss: 93.3275 - val_mae: 6.9162\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 55.0258 - mae: 5.3291 - val_loss: 93.2671 - val_mae: 6.9669\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.1545 - mae: 5.3689 - val_loss: 93.6780 - val_mae: 6.9446\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 53.5708 - mae: 5.3689 - val_loss: 94.3414 - val_mae: 6.9677\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 53.0320 - mae: 5.3136 - val_loss: 93.3926 - val_mae: 6.9494\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.2399 - mae: 5.3200 - val_loss: 93.3535 - val_mae: 6.9505\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 51.9192 - mae: 5.3190 - val_loss: 94.2404 - val_mae: 6.9861\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 52.0027 - mae: 5.2909 - val_loss: 96.0331 - val_mae: 7.0262\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 52.6768 - mae: 5.2143 - val_loss: 96.6475 - val_mae: 7.1343\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 50.6876 - mae: 5.2195 - val_loss: 94.7099 - val_mae: 7.0082\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 50.2763 - mae: 5.2897 - val_loss: 95.6184 - val_mae: 7.0468\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 50.4895 - mae: 5.1164 - val_loss: 98.1961 - val_mae: 7.1779\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 49.1714 - mae: 5.0700 - val_loss: 95.9916 - val_mae: 7.0596\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 49.3232 - mae: 5.2312 - val_loss: 96.1899 - val_mae: 7.0387\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 48.0548 - mae: 5.0930 - val_loss: 98.6890 - val_mae: 7.1816\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 47.8663 - mae: 5.0259 - val_loss: 96.4367 - val_mae: 7.0943\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 47.2252 - mae: 5.0549 - val_loss: 96.9521 - val_mae: 7.0982\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 46.6385 - mae: 5.0415 - val_loss: 97.2743 - val_mae: 7.1310\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 46.1091 - mae: 4.9433 - val_loss: 98.1185 - val_mae: 7.1595\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 45.7885 - mae: 4.9251 - val_loss: 98.5813 - val_mae: 7.1414\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 45.3050 - mae: 4.8975 - val_loss: 98.7533 - val_mae: 7.1646\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 45.5267 - mae: 4.9850 - val_loss: 98.2146 - val_mae: 7.1668\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 45.3059 - mae: 4.8420 - val_loss: 100.5811 - val_mae: 7.2485\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 44.8710 - mae: 4.8810 - val_loss: 99.2681 - val_mae: 7.1867\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 43.9245 - mae: 4.8178 - val_loss: 100.0723 - val_mae: 7.2346\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 43.3072 - mae: 4.7906 - val_loss: 98.9881 - val_mae: 7.1986\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 43.5941 - mae: 4.8860 - val_loss: 100.5624 - val_mae: 7.2720\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 44.1678 - mae: 4.7781 - val_loss: 101.6146 - val_mae: 7.2951\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 43.0568 - mae: 4.8456 - val_loss: 98.8714 - val_mae: 7.1722\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 42.0576 - mae: 4.7766 - val_loss: 101.0781 - val_mae: 7.2420\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 41.9894 - mae: 4.6189 - val_loss: 101.9555 - val_mae: 7.3024\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 41.2761 - mae: 4.6639 - val_loss: 100.6154 - val_mae: 7.2661\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 40.9802 - mae: 4.7039 - val_loss: 102.4358 - val_mae: 7.3212\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 40.7341 - mae: 4.5364 - val_loss: 101.9495 - val_mae: 7.2818\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 41.3691 - mae: 4.7225 - val_loss: 100.9806 - val_mae: 7.2791\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 41.3428 - mae: 4.5612 - val_loss: 104.1619 - val_mae: 7.4058\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 39.6886 - mae: 4.4748 - val_loss: 101.9326 - val_mae: 7.2848\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 39.6235 - mae: 4.6239 - val_loss: 101.4067 - val_mae: 7.3205\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 40.3723 - mae: 4.5336 - val_loss: 103.1042 - val_mae: 7.3802\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 38.8637 - mae: 4.5180 - val_loss: 101.8346 - val_mae: 7.2989\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 38.5533 - mae: 4.5179 - val_loss: 103.9461 - val_mae: 7.3540\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 38.4932 - mae: 4.4282 - val_loss: 103.0968 - val_mae: 7.3252\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.4956 - mae: 4.4633 - val_loss: 104.4717 - val_mae: 7.3514\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 38.3538 - mae: 4.4482 - val_loss: 104.1002 - val_mae: 7.4369\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 38.8276 - mae: 4.4905 - val_loss: 102.5258 - val_mae: 7.3496\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 37.0859 - mae: 4.3902 - val_loss: 104.9187 - val_mae: 7.3988\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 37.2286 - mae: 4.4495 - val_loss: 103.6243 - val_mae: 7.3400\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.8088 - mae: 4.3844 - val_loss: 103.9733 - val_mae: 7.4031\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 35.9669 - mae: 4.3055 - val_loss: 105.0335 - val_mae: 7.4424\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 36.0436 - mae: 4.2518 - val_loss: 104.1516 - val_mae: 7.4053\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 35.6565 - mae: 4.2346 - val_loss: 104.2404 - val_mae: 7.3937\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 36.0177 - mae: 4.3449 - val_loss: 105.0931 - val_mae: 7.4176\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 35.2714 - mae: 4.2873 - val_loss: 106.5046 - val_mae: 7.4837\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 35.2379 - mae: 4.1802 - val_loss: 106.0860 - val_mae: 7.4678\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.5848 - mae: 4.1606 - val_loss: 103.6502 - val_mae: 7.3930\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.4171 - mae: 4.2790 - val_loss: 104.7106 - val_mae: 7.4282\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.4751 - mae: 4.1256 - val_loss: 108.7201 - val_mae: 7.5343\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 33.9693 - mae: 4.0868 - val_loss: 107.4451 - val_mae: 7.4590\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 33.2979 - mae: 4.1472 - val_loss: 105.1995 - val_mae: 7.4429\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.0810 - mae: 4.0896 - val_loss: 106.0549 - val_mae: 7.4956\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.7769 - mae: 4.0736 - val_loss: 106.3426 - val_mae: 7.5086\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 33.1948 - mae: 4.0924 - val_loss: 107.2568 - val_mae: 7.5051\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 32.2845 - mae: 4.0118 - val_loss: 107.1599 - val_mae: 7.4609\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.2246 - mae: 4.1714 - val_loss: 106.6716 - val_mae: 7.4917\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.0467 - mae: 3.9911 - val_loss: 110.3098 - val_mae: 7.6145\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.9692 - mae: 3.9671 - val_loss: 106.7074 - val_mae: 7.5270\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.2579 - mae: 4.0123 - val_loss: 108.0926 - val_mae: 7.5373\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 30.7479 - mae: 3.9080 - val_loss: 107.7041 - val_mae: 7.5382\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 30.8645 - mae: 3.9350 - val_loss: 108.0243 - val_mae: 7.5218\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.2841 - mae: 3.8672 - val_loss: 108.6402 - val_mae: 7.5481\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.3343 - mae: 3.9011 - val_loss: 109.1261 - val_mae: 7.5638\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.9397 - mae: 3.8779 - val_loss: 109.0261 - val_mae: 7.6005\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 30.1145 - mae: 3.8955 - val_loss: 110.7551 - val_mae: 7.6354\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.0158 - mae: 3.8766 - val_loss: 106.8434 - val_mae: 7.4872\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 28.9607 - mae: 3.8317 - val_loss: 110.8293 - val_mae: 7.6380\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 30.0493 - mae: 3.8405 - val_loss: 109.5861 - val_mae: 7.5693\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 30.1890 - mae: 3.9261 - val_loss: 109.2632 - val_mae: 7.5930\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.9365 - mae: 3.8202 - val_loss: 112.3336 - val_mae: 7.6689\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 28.3909 - mae: 3.6897 - val_loss: 108.9991 - val_mae: 7.5738\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.9199 - mae: 3.9041 - val_loss: 108.0754 - val_mae: 7.5678\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.4768 - mae: 3.6717 - val_loss: 112.2794 - val_mae: 7.6661\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.8741 - mae: 3.7224 - val_loss: 110.4351 - val_mae: 7.6298\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.3808 - mae: 3.6300 - val_loss: 112.6363 - val_mae: 7.6930\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 27.1891 - mae: 3.6951 - val_loss: 109.7510 - val_mae: 7.6218\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.7604 - mae: 3.7540 - val_loss: 112.4272 - val_mae: 7.6664\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.8966 - mae: 3.6802 - val_loss: 112.0018 - val_mae: 7.6390\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 28.3547 - mae: 3.8620 - val_loss: 108.3330 - val_mae: 7.6110\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 27.2509 - mae: 3.6455 - val_loss: 114.6480 - val_mae: 7.7679\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 26.4573 - mae: 3.5800 - val_loss: 112.9257 - val_mae: 7.6665\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.5755 - mae: 3.6571 - val_loss: 112.5866 - val_mae: 7.6769\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.8737 - mae: 3.4952 - val_loss: 113.5686 - val_mae: 7.7176\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.0542 - mae: 3.6025 - val_loss: 110.4697 - val_mae: 7.6037\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.3712 - mae: 3.5271 - val_loss: 112.7198 - val_mae: 7.6700\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.0401 - mae: 3.4526 - val_loss: 111.1821 - val_mae: 7.6343\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 26.4328 - mae: 3.7158 - val_loss: 110.9785 - val_mae: 7.6702\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.0128 - mae: 3.6424 - val_loss: 112.9903 - val_mae: 7.6795\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.4459 - mae: 3.4115 - val_loss: 111.7459 - val_mae: 7.6093\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 24.1691 - mae: 3.4614 - val_loss: 111.8807 - val_mae: 7.6373\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.8671 - mae: 3.4058 - val_loss: 111.3226 - val_mae: 7.6302\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 23.8637 - mae: 3.3984 - val_loss: 112.7522 - val_mae: 7.7025\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 23.4523 - mae: 3.3687 - val_loss: 114.9582 - val_mae: 7.7241\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3405 - mae: 3.2690 - val_loss: 112.0341 - val_mae: 7.6712\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 23.0306 - mae: 3.3756 - val_loss: 112.3560 - val_mae: 7.6654\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.0017 - mae: 3.3456 - val_loss: 112.1351 - val_mae: 7.6646\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.6922 - mae: 3.3456 - val_loss: 113.1948 - val_mae: 7.6998\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9036 - mae: 3.3396 - val_loss: 115.4330 - val_mae: 7.7650\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.3111 - mae: 3.3501 - val_loss: 113.6954 - val_mae: 7.6927\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.3519 - mae: 3.2905 - val_loss: 113.7953 - val_mae: 7.7447\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.0111 - mae: 3.2396 - val_loss: 115.1889 - val_mae: 7.7721\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.4356 - mae: 3.3004 - val_loss: 115.7115 - val_mae: 7.7111\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.0060 - mae: 3.2352 - val_loss: 115.6903 - val_mae: 7.7218\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.8773 - mae: 3.2610 - val_loss: 112.4477 - val_mae: 7.6442\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.8294 - mae: 3.2739 - val_loss: 112.2003 - val_mae: 7.6291\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.9217 - mae: 3.2109 - val_loss: 115.9545 - val_mae: 7.7447\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8293 - mae: 3.3013 - val_loss: 113.6997 - val_mae: 7.7131\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 20.9042 - mae: 3.2159 - val_loss: 117.8293 - val_mae: 7.7968\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.1135 - mae: 3.0899 - val_loss: 114.1786 - val_mae: 7.6470\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 20.3954 - mae: 3.0647 - val_loss: 112.5684 - val_mae: 7.6275\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.0615 - mae: 3.1263 - val_loss: 114.7016 - val_mae: 7.6914\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 19.6513 - mae: 3.0390 - val_loss: 115.7842 - val_mae: 7.7339\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 19.3741 - mae: 3.0168 - val_loss: 116.5568 - val_mae: 7.7700\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 19.3073 - mae: 3.0955 - val_loss: 113.8139 - val_mae: 7.6721\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 19.1523 - mae: 3.0290 - val_loss: 116.3012 - val_mae: 7.7283\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.5296 - mae: 3.1172 - val_loss: 116.5097 - val_mae: 7.7552\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 19.1374 - mae: 3.0531 - val_loss: 113.5216 - val_mae: 7.6717\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 19.3272 - mae: 3.0385 - val_loss: 117.4112 - val_mae: 7.7726\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.5585 - mae: 3.0623 - val_loss: 114.8508 - val_mae: 7.7224\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 18.3454 - mae: 2.9951 - val_loss: 121.3021 - val_mae: 7.9110\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 19.1142 - mae: 2.9714 - val_loss: 115.0920 - val_mae: 7.7045\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 17.7981 - mae: 2.9419 - val_loss: 117.2956 - val_mae: 7.7745\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 17.6818 - mae: 2.8938 - val_loss: 116.0155 - val_mae: 7.7355\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 17.3523 - mae: 2.8503 - val_loss: 117.5030 - val_mae: 7.7571\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.9830 - mae: 2.8041 - val_loss: 116.7557 - val_mae: 7.7523\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 17.0921 - mae: 2.7951 - val_loss: 116.4316 - val_mae: 7.7293\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 17.4698 - mae: 2.8496 - val_loss: 118.9629 - val_mae: 7.7936\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 17.0553 - mae: 2.8218 - val_loss: 116.7795 - val_mae: 7.7477\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.9178 - mae: 2.8492 - val_loss: 117.2217 - val_mae: 7.7616\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 16.7811 - mae: 2.7622 - val_loss: 117.7339 - val_mae: 7.7555\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 17.2735 - mae: 2.8795 - val_loss: 118.9822 - val_mae: 7.8133\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 16.1625 - mae: 2.7670 - val_loss: 118.8223 - val_mae: 7.8206\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 16.2689 - mae: 2.7810 - val_loss: 117.3832 - val_mae: 7.7291\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 16.4123 - mae: 2.7924 - val_loss: 119.9297 - val_mae: 7.8099\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 15.4422 - mae: 2.6801 - val_loss: 115.8638 - val_mae: 7.7292\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.7899 - mae: 2.7426 - val_loss: 121.4309 - val_mae: 7.8841\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 15.7126 - mae: 2.7192 - val_loss: 117.5617 - val_mae: 7.7547\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 15.4227 - mae: 2.6419 - val_loss: 121.7868 - val_mae: 7.8793\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 15.3091 - mae: 2.6618 - val_loss: 117.9642 - val_mae: 7.7736\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.9228 - mae: 2.6355 - val_loss: 119.9877 - val_mae: 7.8398\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 15.0924 - mae: 2.6602 - val_loss: 117.9646 - val_mae: 7.7704\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.6693 - mae: 2.6253 - val_loss: 121.2584 - val_mae: 7.8315\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.9580 - mae: 2.6047 - val_loss: 116.6237 - val_mae: 7.7342\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.7364 - mae: 2.6269 - val_loss: 120.1331 - val_mae: 7.8367\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.4627 - mae: 2.7295 - val_loss: 120.0314 - val_mae: 7.8542\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 14.3459 - mae: 2.6458 - val_loss: 121.4647 - val_mae: 7.8367\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.2244 - mae: 2.5336 - val_loss: 115.2930 - val_mae: 7.6831\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.8932 - mae: 2.5367 - val_loss: 120.8836 - val_mae: 7.8500\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.1730 - mae: 2.5693 - val_loss: 121.2020 - val_mae: 7.8546\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.3746 - mae: 2.4616 - val_loss: 120.3399 - val_mae: 7.8136\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.5709 - mae: 2.4676 - val_loss: 119.1945 - val_mae: 7.8057\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 13.6134 - mae: 2.4262 - val_loss: 119.6555 - val_mae: 7.8250\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.5270 - mae: 2.5087 - val_loss: 121.3600 - val_mae: 7.8707\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.3732 - mae: 2.4075 - val_loss: 119.9946 - val_mae: 7.8225\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.6164 - mae: 2.4925 - val_loss: 118.1274 - val_mae: 7.7706\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 12.9036 - mae: 2.3577 - val_loss: 121.9459 - val_mae: 7.8800\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.1216 - mae: 2.4178 - val_loss: 119.8561 - val_mae: 7.8218\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.3505 - mae: 2.6246 - val_loss: 122.9582 - val_mae: 7.9247\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.5854 - mae: 2.5787 - val_loss: 119.2048 - val_mae: 7.7876\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.3505 - mae: 2.5101 - val_loss: 125.8732 - val_mae: 7.9541\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.9581 - mae: 2.3886 - val_loss: 118.2749 - val_mae: 7.7418\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 12.1427 - mae: 2.3162 - val_loss: 121.5719 - val_mae: 7.8813\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 11.9929 - mae: 2.3011 - val_loss: 120.5232 - val_mae: 7.8465\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 11.6493 - mae: 2.2520 - val_loss: 121.2121 - val_mae: 7.8221\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 11.4547 - mae: 2.2261 - val_loss: 121.8018 - val_mae: 7.8217\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.3769 - mae: 2.2314 - val_loss: 121.7983 - val_mae: 7.8709\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.6946 - mae: 2.2740 - val_loss: 120.6101 - val_mae: 7.8135\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.6831 - mae: 2.2526 - val_loss: 123.4672 - val_mae: 7.8978\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 11.1741 - mae: 2.1811 - val_loss: 120.1393 - val_mae: 7.8401\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 12.1104 - mae: 2.3442 - val_loss: 123.7054 - val_mae: 7.9335\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.3462 - mae: 2.2750 - val_loss: 120.3658 - val_mae: 7.8668\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.0010 - mae: 2.2174 - val_loss: 123.2598 - val_mae: 7.8619\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 11.0024 - mae: 2.1639 - val_loss: 125.3082 - val_mae: 7.9543\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.2483 - mae: 2.1798 - val_loss: 119.3066 - val_mae: 7.8014\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 10.6371 - mae: 2.1601 - val_loss: 124.7036 - val_mae: 7.9588\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.3890 - mae: 2.2857 - val_loss: 119.7053 - val_mae: 7.7748\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.2857 - mae: 2.3067 - val_loss: 125.0531 - val_mae: 7.9437\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 10.8046 - mae: 2.2114 - val_loss: 118.0403 - val_mae: 7.7684\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.7448 - mae: 2.3548 - val_loss: 125.0950 - val_mae: 7.9378\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.3093 - mae: 2.0954 - val_loss: 123.8266 - val_mae: 7.8979\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 10.1457 - mae: 2.0708 - val_loss: 123.7274 - val_mae: 7.8931\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.7665 - mae: 2.0397 - val_loss: 123.2224 - val_mae: 7.8545\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.6521 - mae: 1.9993 - val_loss: 121.9386 - val_mae: 7.8493\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.5425 - mae: 1.9642 - val_loss: 123.9656 - val_mae: 7.8663\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.8600 - mae: 2.0398 - val_loss: 122.0275 - val_mae: 7.8383\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 9.7173 - mae: 2.0389 - val_loss: 124.4238 - val_mae: 7.9026\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.5914 - mae: 1.9965 - val_loss: 123.7753 - val_mae: 7.9047\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.3043 - mae: 2.0160 - val_loss: 122.2499 - val_mae: 7.8657\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 9.4637 - mae: 2.0244 - val_loss: 122.6000 - val_mae: 7.8399\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.9410 - mae: 1.8840 - val_loss: 124.8140 - val_mae: 7.9220\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.7165 - mae: 1.8554 - val_loss: 122.4669 - val_mae: 7.8538\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.7718 - mae: 1.9043 - val_loss: 124.2286 - val_mae: 7.9172\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.7317 - mae: 1.8921 - val_loss: 123.4977 - val_mae: 7.8856\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 8.5778 - mae: 1.8670 - val_loss: 124.2539 - val_mae: 7.8768\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.6983 - mae: 1.8426 - val_loss: 123.2535 - val_mae: 7.8713\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.9287 - mae: 1.9474 - val_loss: 121.6842 - val_mae: 7.8586\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 8.4674 - mae: 1.8712 - val_loss: 126.5587 - val_mae: 7.9933\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.6449 - mae: 1.9051 - val_loss: 123.5897 - val_mae: 7.8934\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 130.9081 - mae: 8.2826\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 40ms/step - loss: 598.0004 - mae: 22.5128 - val_loss: 628.4192 - val_mae: 23.2311\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 565.7829 - mae: 21.7945 - val_loss: 598.0619 - val_mae: 22.5498\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 532.7258 - mae: 21.0297 - val_loss: 562.3177 - val_mae: 21.7149\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 492.9176 - mae: 20.0681 - val_loss: 517.9989 - val_mae: 20.6262\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 444.9597 - mae: 18.7704 - val_loss: 461.5639 - val_mae: 19.2071\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 382.2198 - mae: 16.9872 - val_loss: 391.7002 - val_mae: 17.3236\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 304.6801 - mae: 14.5663 - val_loss: 313.3455 - val_mae: 15.0078\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 229.6997 - mae: 11.8414 - val_loss: 236.3441 - val_mae: 12.3680\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 163.6515 - mae: 9.5169 - val_loss: 182.7615 - val_mae: 10.0955\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 130.9635 - mae: 8.5330 - val_loss: 163.1208 - val_mae: 9.4323\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 124.2569 - mae: 8.4463 - val_loss: 151.4006 - val_mae: 9.0721\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 115.6635 - mae: 8.1473 - val_loss: 139.0828 - val_mae: 8.6172\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 104.6983 - mae: 7.6279 - val_loss: 133.8948 - val_mae: 8.4353\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 98.2567 - mae: 7.2620 - val_loss: 131.6952 - val_mae: 8.3692\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 94.4184 - mae: 7.1474 - val_loss: 128.3301 - val_mae: 8.2719\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 91.8321 - mae: 7.0706 - val_loss: 124.5407 - val_mae: 8.1386\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 88.8999 - mae: 6.9862 - val_loss: 122.3582 - val_mae: 8.0364\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 87.1817 - mae: 6.9601 - val_loss: 121.4559 - val_mae: 8.0104\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 86.5885 - mae: 6.9708 - val_loss: 120.6797 - val_mae: 7.9860\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 85.2851 - mae: 6.9002 - val_loss: 120.3153 - val_mae: 7.9625\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.3341 - mae: 6.8403 - val_loss: 120.4583 - val_mae: 7.9463\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 83.4269 - mae: 6.7927 - val_loss: 120.0632 - val_mae: 7.9186\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 82.7824 - mae: 6.7743 - val_loss: 119.5737 - val_mae: 7.8833\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.2260 - mae: 6.7678 - val_loss: 118.9124 - val_mae: 7.8409\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 82.2634 - mae: 6.7481 - val_loss: 119.7672 - val_mae: 7.8625\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 81.2075 - mae: 6.6810 - val_loss: 118.8608 - val_mae: 7.8157\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 80.6473 - mae: 6.6914 - val_loss: 118.4706 - val_mae: 7.7942\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 80.3689 - mae: 6.7203 - val_loss: 118.1390 - val_mae: 7.7650\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 80.0313 - mae: 6.6959 - val_loss: 118.7237 - val_mae: 7.7869\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 79.1728 - mae: 6.6507 - val_loss: 118.4017 - val_mae: 7.7634\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 78.8178 - mae: 6.6257 - val_loss: 118.6744 - val_mae: 7.7581\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 78.3424 - mae: 6.5904 - val_loss: 118.7974 - val_mae: 7.7494\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 77.9235 - mae: 6.5694 - val_loss: 118.5719 - val_mae: 7.7256\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 77.7536 - mae: 6.5757 - val_loss: 118.8519 - val_mae: 7.7297\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 77.2460 - mae: 6.5570 - val_loss: 119.6140 - val_mae: 7.7515\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 76.8622 - mae: 6.5417 - val_loss: 119.1896 - val_mae: 7.7252\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 76.5701 - mae: 6.5553 - val_loss: 117.9049 - val_mae: 7.6615\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 76.1252 - mae: 6.5312 - val_loss: 117.6295 - val_mae: 7.6454\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 76.1705 - mae: 6.5310 - val_loss: 117.8513 - val_mae: 7.6425\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 75.3688 - mae: 6.4907 - val_loss: 118.5501 - val_mae: 7.6647\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 75.1856 - mae: 6.4894 - val_loss: 119.2273 - val_mae: 7.6860\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 75.2607 - mae: 6.4602 - val_loss: 119.3255 - val_mae: 7.6798\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 74.8781 - mae: 6.4637 - val_loss: 118.1196 - val_mae: 7.6210\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 74.3755 - mae: 6.4978 - val_loss: 117.4913 - val_mae: 7.6095\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 73.7986 - mae: 6.4607 - val_loss: 118.2217 - val_mae: 7.6435\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 73.9091 - mae: 6.4265 - val_loss: 119.6118 - val_mae: 7.6747\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 73.3204 - mae: 6.4121 - val_loss: 119.4175 - val_mae: 7.6572\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 73.3561 - mae: 6.4444 - val_loss: 117.8267 - val_mae: 7.5881\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 72.7897 - mae: 6.4373 - val_loss: 118.6909 - val_mae: 7.6292\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 72.6652 - mae: 6.3895 - val_loss: 119.7070 - val_mae: 7.6473\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.2482 - mae: 6.3996 - val_loss: 118.7401 - val_mae: 7.6120\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 71.9513 - mae: 6.4232 - val_loss: 118.4297 - val_mae: 7.6105\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 71.7019 - mae: 6.3891 - val_loss: 119.3297 - val_mae: 7.6403\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 71.3240 - mae: 6.3633 - val_loss: 119.4011 - val_mae: 7.6416\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 71.2967 - mae: 6.3755 - val_loss: 118.7102 - val_mae: 7.6050\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 70.7004 - mae: 6.3628 - val_loss: 118.3850 - val_mae: 7.5832\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 70.7777 - mae: 6.3258 - val_loss: 119.0411 - val_mae: 7.5875\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 70.2400 - mae: 6.2894 - val_loss: 119.3585 - val_mae: 7.5827\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 69.7319 - mae: 6.3080 - val_loss: 118.8117 - val_mae: 7.5628\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 69.5736 - mae: 6.3246 - val_loss: 118.8007 - val_mae: 7.5773\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 69.4579 - mae: 6.3285 - val_loss: 119.3407 - val_mae: 7.6075\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 69.3496 - mae: 6.3122 - val_loss: 118.8102 - val_mae: 7.5813\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 68.8507 - mae: 6.2684 - val_loss: 118.7929 - val_mae: 7.5659\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 69.5464 - mae: 6.3443 - val_loss: 118.3811 - val_mae: 7.5390\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 68.1351 - mae: 6.2753 - val_loss: 118.9924 - val_mae: 7.5650\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.1183 - mae: 6.2509 - val_loss: 120.8160 - val_mae: 7.6177\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 67.8048 - mae: 6.1700 - val_loss: 119.9479 - val_mae: 7.6009\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 67.8883 - mae: 6.2589 - val_loss: 118.0384 - val_mae: 7.5480\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 67.9003 - mae: 6.3026 - val_loss: 118.8275 - val_mae: 7.5580\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.8647 - mae: 6.1994 - val_loss: 119.5377 - val_mae: 7.5760\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.0544 - mae: 6.1620 - val_loss: 120.9554 - val_mae: 7.6312\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 66.5673 - mae: 6.1746 - val_loss: 119.6932 - val_mae: 7.6090\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 66.2429 - mae: 6.1876 - val_loss: 119.5527 - val_mae: 7.5670\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 65.8168 - mae: 6.1694 - val_loss: 119.1798 - val_mae: 7.5501\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 65.8253 - mae: 6.1424 - val_loss: 118.9314 - val_mae: 7.5215\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 65.1991 - mae: 6.1071 - val_loss: 119.2091 - val_mae: 7.5298\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 64.9628 - mae: 6.0988 - val_loss: 119.5807 - val_mae: 7.5367\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 64.7458 - mae: 6.0970 - val_loss: 120.1262 - val_mae: 7.5720\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 64.6747 - mae: 6.1133 - val_loss: 119.9455 - val_mae: 7.5576\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 64.6189 - mae: 6.1273 - val_loss: 118.5462 - val_mae: 7.5619\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 64.2475 - mae: 6.0747 - val_loss: 120.0224 - val_mae: 7.5964\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 63.9905 - mae: 6.0279 - val_loss: 119.5819 - val_mae: 7.5620\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 63.5382 - mae: 6.0390 - val_loss: 119.7838 - val_mae: 7.5517\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 63.5320 - mae: 6.0691 - val_loss: 118.7076 - val_mae: 7.4909\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 63.2310 - mae: 6.0296 - val_loss: 119.1681 - val_mae: 7.5097\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 62.7258 - mae: 6.0057 - val_loss: 119.2966 - val_mae: 7.5358\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 62.5438 - mae: 6.0095 - val_loss: 119.3223 - val_mae: 7.5339\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 62.5396 - mae: 5.9920 - val_loss: 120.3483 - val_mae: 7.5748\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 62.0867 - mae: 5.9688 - val_loss: 120.1235 - val_mae: 7.5873\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 61.7597 - mae: 5.9614 - val_loss: 120.4353 - val_mae: 7.5887\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.4415 - mae: 5.9436 - val_loss: 120.3207 - val_mae: 7.5755\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 61.5720 - mae: 5.9448 - val_loss: 119.6758 - val_mae: 7.5618\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 61.2849 - mae: 5.9303 - val_loss: 119.9689 - val_mae: 7.5310\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 60.7576 - mae: 5.8858 - val_loss: 120.1276 - val_mae: 7.5363\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 60.5821 - mae: 5.9079 - val_loss: 120.0728 - val_mae: 7.5380\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.4812 - mae: 5.8993 - val_loss: 120.6029 - val_mae: 7.5756\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.1877 - mae: 5.8722 - val_loss: 120.9559 - val_mae: 7.5888\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 60.0952 - mae: 5.8562 - val_loss: 120.3266 - val_mae: 7.5323\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 59.8495 - mae: 5.8330 - val_loss: 121.0055 - val_mae: 7.5566\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 59.7553 - mae: 5.8384 - val_loss: 121.0277 - val_mae: 7.5731\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 59.7057 - mae: 5.8345 - val_loss: 121.6201 - val_mae: 7.5541\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 58.9735 - mae: 5.7922 - val_loss: 120.1905 - val_mae: 7.5401\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 59.1488 - mae: 5.8014 - val_loss: 120.1726 - val_mae: 7.5465\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.0080 - mae: 5.7896 - val_loss: 121.3791 - val_mae: 7.5750\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 58.5043 - mae: 5.7639 - val_loss: 121.2822 - val_mae: 7.5848\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 57.9364 - mae: 5.7311 - val_loss: 120.4516 - val_mae: 7.5520\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.9824 - mae: 5.7259 - val_loss: 120.9274 - val_mae: 7.5782\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 57.4578 - mae: 5.7032 - val_loss: 121.4929 - val_mae: 7.5623\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 57.3031 - mae: 5.6965 - val_loss: 121.2889 - val_mae: 7.5604\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 56.8997 - mae: 5.6791 - val_loss: 121.6842 - val_mae: 7.5752\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 56.5790 - mae: 5.6458 - val_loss: 121.1320 - val_mae: 7.5517\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 56.3695 - mae: 5.6294 - val_loss: 121.4949 - val_mae: 7.5632\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 56.3893 - mae: 5.6113 - val_loss: 120.8738 - val_mae: 7.5379\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 55.8734 - mae: 5.5867 - val_loss: 120.3493 - val_mae: 7.5062\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 55.7961 - mae: 5.5814 - val_loss: 122.1337 - val_mae: 7.5723\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 55.6234 - mae: 5.5894 - val_loss: 122.4314 - val_mae: 7.5950\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 55.9793 - mae: 5.6195 - val_loss: 121.3349 - val_mae: 7.6083\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 55.3138 - mae: 5.5472 - val_loss: 122.6471 - val_mae: 7.5902\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.9872 - mae: 5.5299 - val_loss: 122.0767 - val_mae: 7.5882\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 54.6371 - mae: 5.5437 - val_loss: 121.8421 - val_mae: 7.5832\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 54.1500 - mae: 5.5244 - val_loss: 122.4496 - val_mae: 7.5879\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 53.5820 - mae: 5.4448 - val_loss: 121.4537 - val_mae: 7.5546\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 53.5313 - mae: 5.4465 - val_loss: 121.5640 - val_mae: 7.5829\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 53.3247 - mae: 5.4539 - val_loss: 122.8895 - val_mae: 7.6090\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 52.9436 - mae: 5.4530 - val_loss: 123.1541 - val_mae: 7.6413\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 52.5736 - mae: 5.3832 - val_loss: 123.2344 - val_mae: 7.6314\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 52.5251 - mae: 5.3745 - val_loss: 122.9282 - val_mae: 7.6406\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 52.2667 - mae: 5.3700 - val_loss: 123.1385 - val_mae: 7.6433\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 51.8674 - mae: 5.3587 - val_loss: 123.7085 - val_mae: 7.6532\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.8054 - mae: 5.3559 - val_loss: 123.5404 - val_mae: 7.6273\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 51.4802 - mae: 5.3453 - val_loss: 124.0607 - val_mae: 7.6535\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.3215 - mae: 5.3437 - val_loss: 123.9720 - val_mae: 7.6914\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 50.8947 - mae: 5.2790 - val_loss: 124.9072 - val_mae: 7.6993\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.5583 - mae: 5.3553 - val_loss: 123.6795 - val_mae: 7.6549\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 50.7926 - mae: 5.3078 - val_loss: 124.9800 - val_mae: 7.6764\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 50.6928 - mae: 5.2754 - val_loss: 124.2961 - val_mae: 7.7040\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 49.5736 - mae: 5.2354 - val_loss: 125.1295 - val_mae: 7.6858\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 49.6489 - mae: 5.1968 - val_loss: 124.7638 - val_mae: 7.6729\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 49.1039 - mae: 5.2262 - val_loss: 124.2175 - val_mae: 7.7148\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 48.7532 - mae: 5.1732 - val_loss: 126.3552 - val_mae: 7.7444\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 48.5980 - mae: 5.1428 - val_loss: 126.8436 - val_mae: 7.8035\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 48.5470 - mae: 5.1010 - val_loss: 126.6664 - val_mae: 7.7605\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 49.2899 - mae: 5.2529 - val_loss: 126.5753 - val_mae: 7.7623\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 47.7826 - mae: 5.1330 - val_loss: 125.9580 - val_mae: 7.6987\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.8890 - mae: 5.0850 - val_loss: 127.5312 - val_mae: 7.7737\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 46.8981 - mae: 5.0666 - val_loss: 129.3623 - val_mae: 7.8665\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 47.1667 - mae: 5.1399 - val_loss: 127.6880 - val_mae: 7.7636\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 46.7289 - mae: 5.0453 - val_loss: 128.0298 - val_mae: 7.8017\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 46.1809 - mae: 4.9785 - val_loss: 128.2981 - val_mae: 7.7773\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 46.0292 - mae: 4.9849 - val_loss: 129.3651 - val_mae: 7.8379\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 45.3049 - mae: 4.9457 - val_loss: 128.5275 - val_mae: 7.8200\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 44.9883 - mae: 4.9069 - val_loss: 128.7114 - val_mae: 7.8078\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 44.9175 - mae: 4.9164 - val_loss: 129.5927 - val_mae: 7.8301\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 45.1745 - mae: 4.9740 - val_loss: 129.2887 - val_mae: 7.8701\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 43.9600 - mae: 4.8894 - val_loss: 131.5005 - val_mae: 7.9089\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 44.6995 - mae: 4.8435 - val_loss: 130.9809 - val_mae: 7.8731\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 43.6944 - mae: 4.8024 - val_loss: 130.3030 - val_mae: 7.9293\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 43.6055 - mae: 4.8300 - val_loss: 131.0650 - val_mae: 7.8551\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 42.6587 - mae: 4.7843 - val_loss: 131.6176 - val_mae: 7.8916\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 43.3876 - mae: 4.8917 - val_loss: 132.4008 - val_mae: 7.9331\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 41.8141 - mae: 4.7261 - val_loss: 132.1774 - val_mae: 7.8912\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 42.0235 - mae: 4.7175 - val_loss: 131.7665 - val_mae: 7.9076\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 41.4287 - mae: 4.7794 - val_loss: 132.6879 - val_mae: 7.9290\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.9087 - mae: 4.6719 - val_loss: 134.0583 - val_mae: 7.9678\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 40.5520 - mae: 4.6237 - val_loss: 134.3727 - val_mae: 7.9781\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 40.3019 - mae: 4.6232 - val_loss: 133.6835 - val_mae: 7.9574\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.6143 - mae: 4.6739 - val_loss: 135.7186 - val_mae: 8.0362\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 39.7846 - mae: 4.6521 - val_loss: 134.9025 - val_mae: 8.0189\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.2056 - mae: 4.5621 - val_loss: 135.3354 - val_mae: 8.0087\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.0751 - mae: 4.5462 - val_loss: 135.9634 - val_mae: 8.0489\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 38.6915 - mae: 4.4838 - val_loss: 135.6570 - val_mae: 8.0173\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 38.1260 - mae: 4.4814 - val_loss: 135.8930 - val_mae: 8.0830\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 39.3999 - mae: 4.6187 - val_loss: 137.1405 - val_mae: 8.0959\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 37.1241 - mae: 4.4223 - val_loss: 137.1097 - val_mae: 8.1521\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 38.3334 - mae: 4.5436 - val_loss: 137.8138 - val_mae: 8.0953\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 37.1128 - mae: 4.4332 - val_loss: 138.0788 - val_mae: 8.1425\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 36.4926 - mae: 4.4216 - val_loss: 137.9024 - val_mae: 8.0828\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 36.2119 - mae: 4.3405 - val_loss: 139.1367 - val_mae: 8.1434\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 35.9374 - mae: 4.2990 - val_loss: 138.6972 - val_mae: 8.1154\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 35.5559 - mae: 4.3334 - val_loss: 139.0087 - val_mae: 8.1859\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.1970 - mae: 4.3137 - val_loss: 139.8724 - val_mae: 8.1893\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.8924 - mae: 4.2332 - val_loss: 141.7123 - val_mae: 8.2412\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.5715 - mae: 4.2182 - val_loss: 140.6006 - val_mae: 8.2182\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 34.0168 - mae: 4.2177 - val_loss: 141.0206 - val_mae: 8.2515\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 33.4487 - mae: 4.1603 - val_loss: 140.7488 - val_mae: 8.1933\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 33.6781 - mae: 4.1893 - val_loss: 142.0935 - val_mae: 8.2638\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.3113 - mae: 4.1770 - val_loss: 141.7524 - val_mae: 8.2667\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.7479 - mae: 4.1236 - val_loss: 144.1206 - val_mae: 8.3882\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.3738 - mae: 4.0633 - val_loss: 141.7919 - val_mae: 8.2785\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 32.5346 - mae: 4.1167 - val_loss: 143.7461 - val_mae: 8.3669\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.4415 - mae: 4.0402 - val_loss: 143.7558 - val_mae: 8.3595\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.5670 - mae: 4.0506 - val_loss: 144.7225 - val_mae: 8.3798\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.8190 - mae: 4.1353 - val_loss: 143.9594 - val_mae: 8.3858\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.1749 - mae: 4.0412 - val_loss: 145.6430 - val_mae: 8.4484\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.4557 - mae: 3.9521 - val_loss: 145.1094 - val_mae: 8.4006\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.5095 - mae: 3.9529 - val_loss: 144.0057 - val_mae: 8.3841\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.8130 - mae: 3.9665 - val_loss: 145.6800 - val_mae: 8.4527\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.0905 - mae: 3.8661 - val_loss: 147.7926 - val_mae: 8.5002\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5425 - mae: 3.8682 - val_loss: 148.1425 - val_mae: 8.4902\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.7019 - mae: 3.8567 - val_loss: 145.8660 - val_mae: 8.4442\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.2012 - mae: 3.8320 - val_loss: 148.8282 - val_mae: 8.5572\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.8996 - mae: 3.7725 - val_loss: 149.8378 - val_mae: 8.5725\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 27.5413 - mae: 3.7279 - val_loss: 149.7124 - val_mae: 8.5424\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.7741 - mae: 3.7634 - val_loss: 150.1885 - val_mae: 8.5645\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.0402 - mae: 3.7077 - val_loss: 153.2805 - val_mae: 8.6820\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 27.3615 - mae: 3.8120 - val_loss: 151.6652 - val_mae: 8.6388\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.2679 - mae: 3.8429 - val_loss: 151.9651 - val_mae: 8.6593\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.3328 - mae: 3.6786 - val_loss: 154.0733 - val_mae: 8.6698\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 25.5779 - mae: 3.5751 - val_loss: 154.7947 - val_mae: 8.7370\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.2001 - mae: 3.6800 - val_loss: 152.8705 - val_mae: 8.6921\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6476 - mae: 3.6238 - val_loss: 157.3441 - val_mae: 8.8565\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 25.1306 - mae: 3.5798 - val_loss: 155.4124 - val_mae: 8.7524\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.5031 - mae: 3.5337 - val_loss: 155.7091 - val_mae: 8.8300\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.6771 - mae: 3.4617 - val_loss: 157.5354 - val_mae: 8.8204\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.6697 - mae: 3.4585 - val_loss: 159.2330 - val_mae: 8.8944\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.4938 - mae: 3.4503 - val_loss: 157.2398 - val_mae: 8.8065\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.0749 - mae: 3.3852 - val_loss: 160.0488 - val_mae: 8.9315\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.5222 - mae: 3.4398 - val_loss: 160.4098 - val_mae: 8.9328\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.5565 - mae: 3.3485 - val_loss: 160.3682 - val_mae: 8.8990\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.7603 - mae: 3.3434 - val_loss: 161.3849 - val_mae: 9.0079\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.6604 - mae: 3.3851 - val_loss: 160.4650 - val_mae: 8.9730\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.6995 - mae: 3.5193 - val_loss: 162.6479 - val_mae: 8.9988\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.7332 - mae: 3.4551 - val_loss: 162.5960 - val_mae: 9.0422\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.3720 - mae: 3.2432 - val_loss: 167.4424 - val_mae: 9.1825\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 20.8466 - mae: 3.2602 - val_loss: 163.0896 - val_mae: 9.0691\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.8773 - mae: 3.2460 - val_loss: 166.4065 - val_mae: 9.1336\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.8979 - mae: 3.3071 - val_loss: 167.4678 - val_mae: 9.2094\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 20.3463 - mae: 3.2757 - val_loss: 166.7804 - val_mae: 9.2363\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.0305 - mae: 3.2223 - val_loss: 168.1775 - val_mae: 9.2209\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 19.2858 - mae: 3.0586 - val_loss: 167.7505 - val_mae: 9.2240\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 19.1064 - mae: 3.0814 - val_loss: 169.8867 - val_mae: 9.2583\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 18.8355 - mae: 3.0560 - val_loss: 166.9327 - val_mae: 9.2408\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 18.4415 - mae: 3.0245 - val_loss: 171.1211 - val_mae: 9.2816\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 18.3753 - mae: 3.0283 - val_loss: 170.6915 - val_mae: 9.3262\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 18.3819 - mae: 3.0391 - val_loss: 174.0534 - val_mae: 9.4124\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 17.8326 - mae: 2.9369 - val_loss: 172.4251 - val_mae: 9.3319\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 17.8790 - mae: 2.9517 - val_loss: 173.0609 - val_mae: 9.3936\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 17.7154 - mae: 2.9946 - val_loss: 174.9853 - val_mae: 9.4089\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 17.1275 - mae: 2.9056 - val_loss: 174.5631 - val_mae: 9.4344\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 16.7492 - mae: 2.8631 - val_loss: 178.0713 - val_mae: 9.4841\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 17.1163 - mae: 2.9941 - val_loss: 178.1472 - val_mae: 9.5686\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.7208 - mae: 2.9124 - val_loss: 175.6097 - val_mae: 9.4255\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 16.4168 - mae: 2.9139 - val_loss: 180.1002 - val_mae: 9.5821\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 16.0169 - mae: 2.7611 - val_loss: 179.6001 - val_mae: 9.5313\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 15.8296 - mae: 2.7956 - val_loss: 180.2176 - val_mae: 9.6416\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 15.6724 - mae: 2.7641 - val_loss: 181.0740 - val_mae: 9.6117\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 15.1463 - mae: 2.6968 - val_loss: 182.8211 - val_mae: 9.6078\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.0106 - mae: 2.6955 - val_loss: 182.7081 - val_mae: 9.7050\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 15.6198 - mae: 2.8290 - val_loss: 186.5899 - val_mae: 9.6582\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.9169 - mae: 3.0010 - val_loss: 183.9588 - val_mae: 9.7783\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.6713 - mae: 2.9409 - val_loss: 187.1290 - val_mae: 9.7855\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.6757 - mae: 2.7284 - val_loss: 185.3087 - val_mae: 9.7198\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.6875 - mae: 2.6736 - val_loss: 186.3567 - val_mae: 9.7553\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.2259 - mae: 2.7211 - val_loss: 188.7508 - val_mae: 9.7618\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.9357 - mae: 2.6146 - val_loss: 186.8244 - val_mae: 9.8096\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 13.3765 - mae: 2.5508 - val_loss: 191.8149 - val_mae: 9.9023\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 13.5489 - mae: 2.5941 - val_loss: 191.5198 - val_mae: 9.8756\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.1504 - mae: 2.5549 - val_loss: 192.1727 - val_mae: 9.8963\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 13.6282 - mae: 2.5837 - val_loss: 192.3847 - val_mae: 9.9177\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.7429 - mae: 2.6357 - val_loss: 193.1411 - val_mae: 9.9476\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.2316 - mae: 2.5962 - val_loss: 194.9941 - val_mae: 10.1071\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 13.3473 - mae: 2.6254 - val_loss: 190.6867 - val_mae: 9.7935\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.0631 - mae: 2.7445 - val_loss: 197.9723 - val_mae: 10.1463\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.4366 - mae: 2.6170 - val_loss: 192.5750 - val_mae: 9.9021\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 13.0909 - mae: 2.5553 - val_loss: 203.0714 - val_mae: 10.2089\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.1145 - mae: 2.7352 - val_loss: 196.9570 - val_mae: 10.0485\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.1277 - mae: 2.7226 - val_loss: 195.9824 - val_mae: 9.9696\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.4103 - mae: 2.6920 - val_loss: 193.0706 - val_mae: 9.9748\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 12.9201 - mae: 2.4987 - val_loss: 200.7425 - val_mae: 10.0932\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 11.5304 - mae: 2.4070 - val_loss: 197.3799 - val_mae: 10.0811\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 11.2056 - mae: 2.3332 - val_loss: 198.0593 - val_mae: 10.1098\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.9218 - mae: 2.2414 - val_loss: 201.5404 - val_mae: 10.1399\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.6301 - mae: 2.2268 - val_loss: 200.7344 - val_mae: 10.1223\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.8229 - mae: 2.2696 - val_loss: 203.7197 - val_mae: 10.1889\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 11.4313 - mae: 2.4429 - val_loss: 204.0293 - val_mae: 10.3158\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.1703 - mae: 2.3865 - val_loss: 199.0488 - val_mae: 10.0074\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.3733 - mae: 2.4641 - val_loss: 205.6897 - val_mae: 10.3363\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.1788 - mae: 2.4332 - val_loss: 203.8166 - val_mae: 10.2033\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.5192 - mae: 2.2860 - val_loss: 206.7663 - val_mae: 10.3106\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.7010 - mae: 2.1694 - val_loss: 204.8728 - val_mae: 10.1551\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 9.2687 - mae: 2.0705 - val_loss: 205.9004 - val_mae: 10.3280\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 9.6356 - mae: 2.1444 - val_loss: 205.6865 - val_mae: 10.2792\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.6094 - mae: 2.1602 - val_loss: 205.3737 - val_mae: 10.2064\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.3675 - mae: 2.1772 - val_loss: 212.0405 - val_mae: 10.4318\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 10.0350 - mae: 2.1850 - val_loss: 206.8963 - val_mae: 10.3133\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 9.3940 - mae: 2.1854 - val_loss: 210.7995 - val_mae: 10.4187\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 10.5729 - mae: 2.4298 - val_loss: 209.2160 - val_mae: 10.3115\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.5619 - mae: 2.2046 - val_loss: 214.6455 - val_mae: 10.5241\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.1499 - mae: 2.1765 - val_loss: 206.3994 - val_mae: 10.2369\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.7922 - mae: 2.0575 - val_loss: 215.3513 - val_mae: 10.4695\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.2430 - mae: 2.1766 - val_loss: 210.0373 - val_mae: 10.3280\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 9.0197 - mae: 2.1280 - val_loss: 212.4427 - val_mae: 10.4576\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.2787 - mae: 2.1136 - val_loss: 216.1825 - val_mae: 10.4347\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.8948 - mae: 2.1167 - val_loss: 211.5295 - val_mae: 10.4465\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.2229 - mae: 1.9795 - val_loss: 216.8135 - val_mae: 10.5178\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 8.2471 - mae: 2.0449 - val_loss: 212.7891 - val_mae: 10.4798\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 8.0411 - mae: 1.9389 - val_loss: 216.5236 - val_mae: 10.5600\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 7.6180 - mae: 1.8384 - val_loss: 215.4103 - val_mae: 10.4856\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 7.7338 - mae: 1.8368 - val_loss: 216.4162 - val_mae: 10.5426\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 7.8056 - mae: 1.9266 - val_loss: 215.6652 - val_mae: 10.5747\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 145.1075 - mae: 8.8113\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 638.6548 - mae: 23.4242 - val_loss: 534.8477 - val_mae: 21.1434\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 611.4681 - mae: 22.8221 - val_loss: 507.9351 - val_mae: 20.5050\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 583.1046 - mae: 22.1644 - val_loss: 474.5670 - val_mae: 19.6807\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 544.7695 - mae: 21.2667 - val_loss: 428.7753 - val_mae: 18.4778\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 491.5685 - mae: 19.9441 - val_loss: 366.7153 - val_mae: 16.6895\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 418.7916 - mae: 17.9986 - val_loss: 288.6319 - val_mae: 14.1288\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 333.6570 - mae: 15.3395 - val_loss: 204.2646 - val_mae: 11.2636\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 242.2695 - mae: 12.4180 - val_loss: 139.4880 - val_mae: 8.5626\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 177.7251 - mae: 10.1345 - val_loss: 121.4579 - val_mae: 7.9245\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 155.4238 - mae: 9.3326 - val_loss: 135.5016 - val_mae: 8.7503\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 142.0381 - mae: 9.1013 - val_loss: 127.0431 - val_mae: 8.5375\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 125.2082 - mae: 8.4494 - val_loss: 111.0473 - val_mae: 7.9064\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 111.8446 - mae: 7.8487 - val_loss: 100.9387 - val_mae: 7.4446\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 106.3419 - mae: 7.5233 - val_loss: 98.8135 - val_mae: 7.3752\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 100.1316 - mae: 7.2632 - val_loss: 99.9133 - val_mae: 7.5052\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 96.5576 - mae: 7.1596 - val_loss: 103.7301 - val_mae: 7.8193\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 94.7179 - mae: 7.1501 - val_loss: 107.6888 - val_mae: 8.0770\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 92.1423 - mae: 7.0751 - val_loss: 105.2025 - val_mae: 7.8928\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 91.1100 - mae: 6.9711 - val_loss: 103.5785 - val_mae: 7.7604\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 90.4132 - mae: 6.9545 - val_loss: 104.8025 - val_mae: 7.8488\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 89.1443 - mae: 6.9222 - val_loss: 105.7045 - val_mae: 7.9075\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 88.8218 - mae: 6.9231 - val_loss: 108.2064 - val_mae: 8.0812\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 87.6504 - mae: 6.8769 - val_loss: 106.4039 - val_mae: 7.9659\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 86.9175 - mae: 6.8285 - val_loss: 106.0442 - val_mae: 7.9503\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 86.3385 - mae: 6.8006 - val_loss: 105.5615 - val_mae: 7.9262\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 85.5718 - mae: 6.7553 - val_loss: 106.1345 - val_mae: 7.9824\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 85.3210 - mae: 6.7266 - val_loss: 105.6689 - val_mae: 7.9593\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 84.7583 - mae: 6.7044 - val_loss: 106.3701 - val_mae: 8.0014\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 84.4732 - mae: 6.7098 - val_loss: 108.3854 - val_mae: 8.1564\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 83.8703 - mae: 6.6818 - val_loss: 106.1354 - val_mae: 8.0112\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 83.3605 - mae: 6.6419 - val_loss: 106.9920 - val_mae: 8.0772\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 82.9555 - mae: 6.6247 - val_loss: 106.1695 - val_mae: 8.0059\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 82.5750 - mae: 6.5974 - val_loss: 106.2310 - val_mae: 8.0003\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 82.1419 - mae: 6.5824 - val_loss: 106.6908 - val_mae: 8.0496\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 81.7921 - mae: 6.5845 - val_loss: 108.0419 - val_mae: 8.1591\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 81.6753 - mae: 6.5922 - val_loss: 106.9659 - val_mae: 8.1037\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 81.3295 - mae: 6.5554 - val_loss: 106.4731 - val_mae: 8.0815\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 81.2684 - mae: 6.5342 - val_loss: 105.1718 - val_mae: 7.9790\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 80.8463 - mae: 6.5170 - val_loss: 107.8049 - val_mae: 8.1632\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 81.2310 - mae: 6.5845 - val_loss: 108.9461 - val_mae: 8.2592\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 80.0886 - mae: 6.5043 - val_loss: 105.7301 - val_mae: 8.0400\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 80.2412 - mae: 6.4336 - val_loss: 103.7144 - val_mae: 7.9044\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 79.9299 - mae: 6.4239 - val_loss: 106.2522 - val_mae: 8.0774\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 79.9319 - mae: 6.5264 - val_loss: 108.5916 - val_mae: 8.2494\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 79.0345 - mae: 6.4716 - val_loss: 106.2245 - val_mae: 8.0864\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 79.0248 - mae: 6.4532 - val_loss: 106.6452 - val_mae: 8.1250\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 78.8365 - mae: 6.4130 - val_loss: 104.7051 - val_mae: 7.9777\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 78.5753 - mae: 6.3758 - val_loss: 104.5962 - val_mae: 7.9965\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 78.0613 - mae: 6.3721 - val_loss: 106.1917 - val_mae: 8.1138\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 77.8919 - mae: 6.3965 - val_loss: 106.9749 - val_mae: 8.1662\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 78.4631 - mae: 6.4624 - val_loss: 107.8306 - val_mae: 8.2251\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 77.9186 - mae: 6.3602 - val_loss: 103.6777 - val_mae: 7.9568\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 77.3824 - mae: 6.3054 - val_loss: 105.1349 - val_mae: 8.0672\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.0539 - mae: 6.3210 - val_loss: 105.2124 - val_mae: 8.0785\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 77.2098 - mae: 6.3683 - val_loss: 106.5907 - val_mae: 8.1844\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 76.4557 - mae: 6.3469 - val_loss: 107.1250 - val_mae: 8.2074\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 76.2814 - mae: 6.2962 - val_loss: 105.2448 - val_mae: 8.0781\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 76.2932 - mae: 6.2843 - val_loss: 105.4551 - val_mae: 8.0904\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 76.1817 - mae: 6.2940 - val_loss: 106.9905 - val_mae: 8.2055\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 75.8747 - mae: 6.2772 - val_loss: 105.5092 - val_mae: 8.1164\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 75.4642 - mae: 6.2654 - val_loss: 106.0077 - val_mae: 8.1582\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 75.3362 - mae: 6.2735 - val_loss: 106.1860 - val_mae: 8.1759\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.1501 - mae: 6.2281 - val_loss: 104.2248 - val_mae: 8.0521\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.9769 - mae: 6.2169 - val_loss: 104.7085 - val_mae: 8.1128\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 75.1473 - mae: 6.2515 - val_loss: 106.1167 - val_mae: 8.1973\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 74.6428 - mae: 6.2308 - val_loss: 104.4997 - val_mae: 8.1061\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 74.4187 - mae: 6.1764 - val_loss: 104.2995 - val_mae: 8.0781\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 74.5192 - mae: 6.1656 - val_loss: 103.5040 - val_mae: 8.0436\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 74.0702 - mae: 6.1776 - val_loss: 105.1733 - val_mae: 8.1625\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 73.6900 - mae: 6.2010 - val_loss: 106.8116 - val_mae: 8.2642\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 73.9617 - mae: 6.1941 - val_loss: 105.6732 - val_mae: 8.1949\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 73.3659 - mae: 6.1719 - val_loss: 106.1034 - val_mae: 8.2286\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 74.1739 - mae: 6.2672 - val_loss: 107.7349 - val_mae: 8.3290\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 73.7790 - mae: 6.1782 - val_loss: 101.7059 - val_mae: 7.9256\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 73.2144 - mae: 6.0997 - val_loss: 103.1340 - val_mae: 8.0391\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 72.7359 - mae: 6.1111 - val_loss: 106.8562 - val_mae: 8.2894\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 72.3927 - mae: 6.1576 - val_loss: 106.5488 - val_mae: 8.2613\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.2435 - mae: 6.1589 - val_loss: 105.9392 - val_mae: 8.2228\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 72.5076 - mae: 6.0836 - val_loss: 102.6291 - val_mae: 8.0095\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 72.1681 - mae: 6.0875 - val_loss: 105.7721 - val_mae: 8.2328\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 71.3909 - mae: 6.1240 - val_loss: 106.1787 - val_mae: 8.2519\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 71.6702 - mae: 6.0743 - val_loss: 103.8346 - val_mae: 8.0900\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 71.1159 - mae: 6.0456 - val_loss: 106.3399 - val_mae: 8.2633\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 70.8609 - mae: 6.0883 - val_loss: 106.0793 - val_mae: 8.2615\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 70.4786 - mae: 6.0482 - val_loss: 104.4480 - val_mae: 8.1569\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 70.4033 - mae: 6.0355 - val_loss: 104.9561 - val_mae: 8.1931\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 70.1444 - mae: 6.0122 - val_loss: 103.7465 - val_mae: 8.1207\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 70.0616 - mae: 5.9925 - val_loss: 103.0711 - val_mae: 8.0906\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 69.5175 - mae: 5.9646 - val_loss: 104.3379 - val_mae: 8.1687\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 69.7851 - mae: 6.0403 - val_loss: 107.5547 - val_mae: 8.3748\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 69.5158 - mae: 6.0256 - val_loss: 104.2454 - val_mae: 8.1619\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 68.9039 - mae: 5.9811 - val_loss: 105.3874 - val_mae: 8.2484\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 68.5598 - mae: 5.9781 - val_loss: 104.0299 - val_mae: 8.1580\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 68.6239 - mae: 5.9633 - val_loss: 105.8645 - val_mae: 8.2676\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.2264 - mae: 5.9836 - val_loss: 104.7213 - val_mae: 8.2006\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 67.7173 - mae: 5.9247 - val_loss: 104.0707 - val_mae: 8.1592\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.8607 - mae: 5.8998 - val_loss: 103.4406 - val_mae: 8.1277\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 67.4348 - mae: 5.8602 - val_loss: 102.5587 - val_mae: 8.0659\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 66.9790 - mae: 5.8576 - val_loss: 104.8962 - val_mae: 8.2230\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 66.6914 - mae: 5.9150 - val_loss: 106.6074 - val_mae: 8.3318\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 66.6016 - mae: 5.9101 - val_loss: 105.1700 - val_mae: 8.2242\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 66.4797 - mae: 5.8428 - val_loss: 103.3518 - val_mae: 8.1075\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 66.3365 - mae: 5.8681 - val_loss: 107.5531 - val_mae: 8.3990\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 66.2501 - mae: 5.8590 - val_loss: 103.4095 - val_mae: 8.1191\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.4359 - mae: 5.7917 - val_loss: 105.2560 - val_mae: 8.2495\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.1957 - mae: 5.7955 - val_loss: 104.2704 - val_mae: 8.1764\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 65.1017 - mae: 5.7876 - val_loss: 104.4703 - val_mae: 8.1724\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 64.7032 - mae: 5.7815 - val_loss: 107.6217 - val_mae: 8.3835\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 64.8452 - mae: 5.8015 - val_loss: 104.7112 - val_mae: 8.1789\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 63.7204 - mae: 5.7235 - val_loss: 105.2393 - val_mae: 8.2405\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 63.4537 - mae: 5.7493 - val_loss: 105.8705 - val_mae: 8.2855\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 63.0808 - mae: 5.7331 - val_loss: 105.5993 - val_mae: 8.2577\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 63.1206 - mae: 5.7401 - val_loss: 105.5785 - val_mae: 8.2430\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 62.6256 - mae: 5.6741 - val_loss: 104.6608 - val_mae: 8.1924\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.1920 - mae: 5.6587 - val_loss: 105.1450 - val_mae: 8.2271\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 61.7391 - mae: 5.6175 - val_loss: 103.1677 - val_mae: 8.0889\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 61.6886 - mae: 5.5940 - val_loss: 103.3723 - val_mae: 8.1290\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 61.0524 - mae: 5.6313 - val_loss: 108.1988 - val_mae: 8.4490\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 61.2917 - mae: 5.6505 - val_loss: 106.7247 - val_mae: 8.3386\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 60.4144 - mae: 5.5951 - val_loss: 105.9851 - val_mae: 8.2843\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 60.0383 - mae: 5.5628 - val_loss: 104.0819 - val_mae: 8.1365\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 59.6810 - mae: 5.5171 - val_loss: 104.5370 - val_mae: 8.1843\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 59.4035 - mae: 5.5170 - val_loss: 105.3999 - val_mae: 8.2580\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 59.1060 - mae: 5.5089 - val_loss: 105.4387 - val_mae: 8.2641\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 58.7942 - mae: 5.5236 - val_loss: 105.8041 - val_mae: 8.2742\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 58.7736 - mae: 5.4895 - val_loss: 104.1860 - val_mae: 8.1526\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.7442 - mae: 5.4152 - val_loss: 105.3955 - val_mae: 8.2321\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 57.5234 - mae: 5.4563 - val_loss: 108.6954 - val_mae: 8.4458\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 57.4917 - mae: 5.4951 - val_loss: 107.6829 - val_mae: 8.3795\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 56.4446 - mae: 5.3696 - val_loss: 103.6395 - val_mae: 8.1058\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 56.3780 - mae: 5.3414 - val_loss: 105.2240 - val_mae: 8.2093\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 55.7479 - mae: 5.3561 - val_loss: 106.1049 - val_mae: 8.2635\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 55.5110 - mae: 5.3165 - val_loss: 105.2042 - val_mae: 8.2286\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.4273 - mae: 5.3520 - val_loss: 108.6313 - val_mae: 8.4443\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.9346 - mae: 5.3060 - val_loss: 106.4607 - val_mae: 8.2689\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 54.7532 - mae: 5.3065 - val_loss: 107.9901 - val_mae: 8.3707\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 53.5714 - mae: 5.2377 - val_loss: 105.2196 - val_mae: 8.1946\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 53.6782 - mae: 5.1984 - val_loss: 105.6389 - val_mae: 8.2448\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 53.2973 - mae: 5.2585 - val_loss: 109.7327 - val_mae: 8.4921\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 52.7654 - mae: 5.2437 - val_loss: 108.2820 - val_mae: 8.3906\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 52.1098 - mae: 5.1323 - val_loss: 106.0683 - val_mae: 8.2863\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 52.3022 - mae: 5.1019 - val_loss: 106.5147 - val_mae: 8.3036\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 51.2664 - mae: 5.1134 - val_loss: 108.0110 - val_mae: 8.3827\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 50.8247 - mae: 5.1100 - val_loss: 109.3338 - val_mae: 8.4383\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 50.7861 - mae: 5.1274 - val_loss: 111.3114 - val_mae: 8.5420\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 50.1077 - mae: 5.0641 - val_loss: 107.5048 - val_mae: 8.3521\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 49.8528 - mae: 5.0514 - val_loss: 109.9195 - val_mae: 8.4886\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 49.8469 - mae: 5.0772 - val_loss: 108.5219 - val_mae: 8.3967\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 49.0816 - mae: 4.9844 - val_loss: 109.3996 - val_mae: 8.4743\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 49.0211 - mae: 5.0058 - val_loss: 110.8694 - val_mae: 8.5514\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 48.4263 - mae: 4.9547 - val_loss: 109.3431 - val_mae: 8.4635\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.8588 - mae: 4.9393 - val_loss: 112.2500 - val_mae: 8.5792\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 47.9798 - mae: 4.9885 - val_loss: 112.8140 - val_mae: 8.6070\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 47.4677 - mae: 4.9864 - val_loss: 111.8099 - val_mae: 8.5593\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 46.9329 - mae: 4.8735 - val_loss: 108.7294 - val_mae: 8.3284\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.3536 - mae: 4.8411 - val_loss: 113.1850 - val_mae: 8.6286\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 46.2487 - mae: 4.9150 - val_loss: 114.8223 - val_mae: 8.7148\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.6061 - mae: 4.8355 - val_loss: 111.3485 - val_mae: 8.5363\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 45.2526 - mae: 4.8078 - val_loss: 114.0482 - val_mae: 8.6595\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 45.3595 - mae: 4.8632 - val_loss: 114.2144 - val_mae: 8.6612\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 46.4414 - mae: 4.8390 - val_loss: 109.0902 - val_mae: 8.3626\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 43.7995 - mae: 4.7392 - val_loss: 118.3365 - val_mae: 8.8779\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.3716 - mae: 4.8506 - val_loss: 115.0979 - val_mae: 8.6624\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.0829 - mae: 4.7589 - val_loss: 112.1693 - val_mae: 8.5002\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 42.8309 - mae: 4.6583 - val_loss: 116.9457 - val_mae: 8.8177\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 43.1642 - mae: 4.7523 - val_loss: 114.2985 - val_mae: 8.6739\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.5676 - mae: 4.6514 - val_loss: 113.2125 - val_mae: 8.5012\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 42.3027 - mae: 4.6396 - val_loss: 117.5462 - val_mae: 8.7677\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 41.4511 - mae: 4.6212 - val_loss: 115.8701 - val_mae: 8.7459\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 41.3674 - mae: 4.5698 - val_loss: 115.7853 - val_mae: 8.6985\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.2900 - mae: 4.6017 - val_loss: 117.3495 - val_mae: 8.7133\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 40.5364 - mae: 4.5277 - val_loss: 116.5269 - val_mae: 8.7792\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 41.0493 - mae: 4.6534 - val_loss: 118.8443 - val_mae: 8.8530\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 40.8691 - mae: 4.5682 - val_loss: 116.7341 - val_mae: 8.6810\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 40.5106 - mae: 4.4931 - val_loss: 118.4327 - val_mae: 8.8455\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 40.3391 - mae: 4.5523 - val_loss: 122.0737 - val_mae: 8.9505\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 40.2118 - mae: 4.5434 - val_loss: 115.9525 - val_mae: 8.6485\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.9681 - mae: 4.4051 - val_loss: 121.6139 - val_mae: 8.9631\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 39.2357 - mae: 4.5168 - val_loss: 119.0688 - val_mae: 8.7962\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.8968 - mae: 4.3727 - val_loss: 118.4441 - val_mae: 8.7632\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 38.0693 - mae: 4.4358 - val_loss: 125.6212 - val_mae: 9.1224\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 37.3840 - mae: 4.3537 - val_loss: 117.5755 - val_mae: 8.6572\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.9919 - mae: 4.2587 - val_loss: 121.2153 - val_mae: 8.8811\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 36.9630 - mae: 4.2895 - val_loss: 122.9652 - val_mae: 8.9926\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 37.1871 - mae: 4.3061 - val_loss: 119.5488 - val_mae: 8.7633\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 35.9117 - mae: 4.2729 - val_loss: 124.1176 - val_mae: 9.0515\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 36.2188 - mae: 4.3291 - val_loss: 122.0222 - val_mae: 8.9186\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 35.7449 - mae: 4.1753 - val_loss: 121.0045 - val_mae: 8.8343\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 35.0528 - mae: 4.1886 - val_loss: 123.9925 - val_mae: 9.0261\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 34.7825 - mae: 4.1812 - val_loss: 123.1317 - val_mae: 8.9748\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 34.8430 - mae: 4.1523 - val_loss: 124.6929 - val_mae: 9.0365\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 35.0010 - mae: 4.1736 - val_loss: 123.6794 - val_mae: 8.9548\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 33.5808 - mae: 4.0752 - val_loss: 126.4314 - val_mae: 9.0582\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.0485 - mae: 4.1584 - val_loss: 123.9419 - val_mae: 8.9607\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.5367 - mae: 4.0958 - val_loss: 125.4025 - val_mae: 9.0557\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.6408 - mae: 4.1138 - val_loss: 126.1606 - val_mae: 9.0523\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 32.9896 - mae: 4.0278 - val_loss: 125.8103 - val_mae: 9.0659\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 32.5887 - mae: 4.0135 - val_loss: 128.4093 - val_mae: 9.1087\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.8510 - mae: 4.0805 - val_loss: 128.6224 - val_mae: 9.1092\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.9033 - mae: 3.9651 - val_loss: 125.9768 - val_mae: 9.0043\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.6500 - mae: 3.9396 - val_loss: 129.0560 - val_mae: 9.1458\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.3799 - mae: 3.9296 - val_loss: 128.2968 - val_mae: 9.1113\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.2529 - mae: 4.0150 - val_loss: 127.1658 - val_mae: 9.0130\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.8866 - mae: 4.1625 - val_loss: 132.6168 - val_mae: 9.2876\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.1286 - mae: 3.9205 - val_loss: 125.8320 - val_mae: 9.0122\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1558 - mae: 3.8648 - val_loss: 134.8390 - val_mae: 9.3847\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.9986 - mae: 3.8582 - val_loss: 127.0213 - val_mae: 8.9364\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.2252 - mae: 3.8418 - val_loss: 132.6547 - val_mae: 9.2797\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 29.6825 - mae: 3.7571 - val_loss: 130.5597 - val_mae: 9.1348\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.4560 - mae: 3.6568 - val_loss: 132.4048 - val_mae: 9.2353\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.1849 - mae: 3.7991 - val_loss: 135.0651 - val_mae: 9.3431\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2544 - mae: 3.7041 - val_loss: 130.5094 - val_mae: 9.0880\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.7028 - mae: 3.7218 - val_loss: 134.7280 - val_mae: 9.3408\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.1490 - mae: 3.7079 - val_loss: 131.0576 - val_mae: 9.1293\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.0839 - mae: 3.6490 - val_loss: 136.4266 - val_mae: 9.3984\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 27.7522 - mae: 3.6460 - val_loss: 134.5047 - val_mae: 9.3036\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.1634 - mae: 3.5644 - val_loss: 137.0476 - val_mae: 9.3651\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.3050 - mae: 3.6289 - val_loss: 135.7768 - val_mae: 9.3332\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.1692 - mae: 3.6209 - val_loss: 134.3130 - val_mae: 9.2431\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.2028 - mae: 3.5528 - val_loss: 139.8312 - val_mae: 9.5358\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.1138 - mae: 3.5366 - val_loss: 134.2592 - val_mae: 9.2412\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.6036 - mae: 3.4640 - val_loss: 139.9457 - val_mae: 9.4595\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.3515 - mae: 3.4365 - val_loss: 137.0422 - val_mae: 9.3465\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 25.7497 - mae: 3.5087 - val_loss: 139.7612 - val_mae: 9.4149\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.0575 - mae: 3.4328 - val_loss: 140.1646 - val_mae: 9.4657\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1780 - mae: 3.4591 - val_loss: 140.0165 - val_mae: 9.4437\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9999 - mae: 3.4456 - val_loss: 140.0105 - val_mae: 9.4323\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.7628 - mae: 3.4898 - val_loss: 140.7400 - val_mae: 9.4416\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.2360 - mae: 3.3559 - val_loss: 142.3235 - val_mae: 9.5188\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.9654 - mae: 3.3677 - val_loss: 141.7177 - val_mae: 9.4495\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.8662 - mae: 3.3368 - val_loss: 141.5710 - val_mae: 9.4756\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.5190 - mae: 3.3041 - val_loss: 142.8285 - val_mae: 9.4968\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.4537 - mae: 3.3787 - val_loss: 142.0332 - val_mae: 9.4679\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.7555 - mae: 3.4138 - val_loss: 145.2634 - val_mae: 9.5936\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.2223 - mae: 3.3078 - val_loss: 139.8010 - val_mae: 9.2985\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9749 - mae: 3.2885 - val_loss: 147.3334 - val_mae: 9.6844\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.7346 - mae: 3.2110 - val_loss: 141.1111 - val_mae: 9.3798\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.1100 - mae: 3.1989 - val_loss: 144.7577 - val_mae: 9.5287\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.6784 - mae: 3.2989 - val_loss: 142.2401 - val_mae: 9.4431\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.2017 - mae: 3.2296 - val_loss: 146.6754 - val_mae: 9.6268\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.1714 - mae: 3.1962 - val_loss: 143.1246 - val_mae: 9.4219\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.8509 - mae: 3.1707 - val_loss: 146.0724 - val_mae: 9.5877\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.4400 - mae: 3.1369 - val_loss: 144.7638 - val_mae: 9.5299\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2604 - mae: 3.0912 - val_loss: 145.4012 - val_mae: 9.4381\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 21.4673 - mae: 3.1189 - val_loss: 145.9615 - val_mae: 9.5033\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5398 - mae: 3.1626 - val_loss: 146.4706 - val_mae: 9.5342\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.6891 - mae: 3.1689 - val_loss: 144.6374 - val_mae: 9.4914\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6120 - mae: 3.2229 - val_loss: 146.8847 - val_mae: 9.5908\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.0467 - mae: 3.0153 - val_loss: 145.8547 - val_mae: 9.4125\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 20.7756 - mae: 3.0669 - val_loss: 151.9382 - val_mae: 9.7637\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.2811 - mae: 3.1240 - val_loss: 147.1560 - val_mae: 9.5275\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7062 - mae: 3.1202 - val_loss: 148.8745 - val_mae: 9.6284\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.0539 - mae: 3.1546 - val_loss: 145.8083 - val_mae: 9.4330\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 20.2159 - mae: 3.0609 - val_loss: 151.8209 - val_mae: 9.7668\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 19.7185 - mae: 2.9887 - val_loss: 145.6933 - val_mae: 9.4357\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 19.3469 - mae: 2.9435 - val_loss: 151.2047 - val_mae: 9.6417\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.2729 - mae: 3.0147 - val_loss: 146.6956 - val_mae: 9.4910\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 18.7452 - mae: 2.8874 - val_loss: 151.7761 - val_mae: 9.7032\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 18.5172 - mae: 2.8455 - val_loss: 148.4234 - val_mae: 9.5702\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 18.8702 - mae: 2.9285 - val_loss: 152.0304 - val_mae: 9.6747\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 18.3989 - mae: 2.8794 - val_loss: 148.7882 - val_mae: 9.6087\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 18.2243 - mae: 2.8322 - val_loss: 150.6018 - val_mae: 9.5895\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 18.1437 - mae: 2.8664 - val_loss: 151.6708 - val_mae: 9.6871\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 18.3987 - mae: 2.8821 - val_loss: 149.7875 - val_mae: 9.5889\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 18.1291 - mae: 2.8581 - val_loss: 150.5011 - val_mae: 9.5599\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 18.1838 - mae: 2.9050 - val_loss: 150.8146 - val_mae: 9.6832\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 17.5910 - mae: 2.8133 - val_loss: 151.6524 - val_mae: 9.6374\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 17.3065 - mae: 2.7703 - val_loss: 151.3023 - val_mae: 9.6812\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 17.4325 - mae: 2.8107 - val_loss: 151.9841 - val_mae: 9.5964\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 17.9452 - mae: 2.9430 - val_loss: 154.5197 - val_mae: 9.8001\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 17.5133 - mae: 2.8725 - val_loss: 151.7582 - val_mae: 9.6958\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 17.6043 - mae: 2.8943 - val_loss: 154.8383 - val_mae: 9.7636\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 16.8549 - mae: 2.7814 - val_loss: 152.6460 - val_mae: 9.7049\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 16.4167 - mae: 2.7068 - val_loss: 152.2776 - val_mae: 9.6651\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.6173 - mae: 2.7149 - val_loss: 153.5946 - val_mae: 9.7300\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 16.7359 - mae: 2.6959 - val_loss: 154.3931 - val_mae: 9.6926\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 16.1015 - mae: 2.7185 - val_loss: 153.6502 - val_mae: 9.6507\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 16.2451 - mae: 2.6970 - val_loss: 153.4509 - val_mae: 9.7174\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 16.3849 - mae: 2.7242 - val_loss: 154.2837 - val_mae: 9.7689\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 16.0382 - mae: 2.6841 - val_loss: 156.0447 - val_mae: 9.7759\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.8268 - mae: 2.7048 - val_loss: 153.1805 - val_mae: 9.7263\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.4730 - mae: 2.6230 - val_loss: 158.6347 - val_mae: 9.8519\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.9509 - mae: 2.7406 - val_loss: 151.7320 - val_mae: 9.6091\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.5237 - mae: 2.8210 - val_loss: 162.1505 - val_mae: 10.0522\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 15.3143 - mae: 2.6564 - val_loss: 150.9376 - val_mae: 9.6188\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 15.8662 - mae: 2.7473 - val_loss: 158.8579 - val_mae: 9.8985\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 15.0491 - mae: 2.6453 - val_loss: 152.3000 - val_mae: 9.6742\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.9659 - mae: 2.6280 - val_loss: 157.1309 - val_mae: 9.7647\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 14.8495 - mae: 2.5878 - val_loss: 155.5362 - val_mae: 9.7575\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 15.3805 - mae: 2.6302 - val_loss: 153.2264 - val_mae: 9.6888\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 14.8671 - mae: 2.6392 - val_loss: 158.9726 - val_mae: 9.9026\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.6031 - mae: 2.6357 - val_loss: 152.0192 - val_mae: 9.5710\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.3620 - mae: 2.7246 - val_loss: 160.5808 - val_mae: 9.9863\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.3775 - mae: 2.4823 - val_loss: 154.4622 - val_mae: 9.6393\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.3127 - mae: 2.4863 - val_loss: 156.1703 - val_mae: 9.7483\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.7175 - mae: 2.4497 - val_loss: 156.9003 - val_mae: 9.8076\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.5584 - mae: 2.4279 - val_loss: 156.8360 - val_mae: 9.7729\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.1941 - mae: 2.4526 - val_loss: 158.0389 - val_mae: 9.7441\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.1192 - mae: 2.5837 - val_loss: 155.6499 - val_mae: 9.7396\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.3808 - mae: 2.5765 - val_loss: 157.5251 - val_mae: 9.7706\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 118.3607 - mae: 8.4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJB6bWP_Y80O"
      },
      "source": [
        "print(mae_list)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwxuiq4cITg"
      },
      "source": [
        "print(np.mean(mae_list))"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}